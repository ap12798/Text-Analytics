{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "peripheral-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "public-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"APsentiments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "false-healthcare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It also increases carbon dioxide emissions whi...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We can already see this happening.\\t</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The ecological disaster is a consequence of no...</td>\n",
       "      <td>postive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We may be dealing with an issue with a level o...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Preventable chronic diseases are Australiaâ€™s...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence sentiment\n",
       "0  It also increases carbon dioxide emissions whi...   neutral\n",
       "1               We can already see this happening.\\t  negative\n",
       "2  The ecological disaster is a consequence of no...   postive\n",
       "3  We may be dealing with an issue with a level o...  negative\n",
       "4  Preventable chronic diseases are Australiaâ€™s...  negative"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cultural-anthropology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     336\n",
       "negative    278\n",
       "postive     185\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "general-reviewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True, norm=\"l2\", stop_words=\"english\", max_df=0.7)\n",
    "X = vectorizer.fit_transform(df.sentence)\n",
    "y = df.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bronze-tobago",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((799, 4619), (799,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-overview",
   "metadata": {},
   "source": [
    "## K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "impossible-dress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1: [0.41071429 0.41964286 0.41071429 0.38392857 0.41441441]\n",
      "0.408, 0.012\n",
      "\n",
      "k = 3: [0.41071429 0.41071429 0.41071429 0.4375     0.41441441]\n",
      "0.417, 0.010\n",
      "\n",
      "k = 10: [0.44642857 0.48214286 0.36607143 0.4375     0.44144144]\n",
      "0.435, 0.038\n",
      "\n",
      "k = 30: [0.47321429 0.46428571 0.36607143 0.46428571 0.45945946]\n",
      "0.445, 0.040\n",
      "\n",
      "Highest score : 0.445 when k = 30\n"
     ]
    }
   ],
   "source": [
    "score_max = 0                      # Score_max is a temoporay variable to store the max score \n",
    "for param in [1, 3, 10, 30]:\n",
    "    model = KNeighborsClassifier(n_neighbors=param)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    print(\"k = {}: {}\\n{:.3f}, {:.3f}\\n\".format(param, scores, scores.mean(), scores.std()))\n",
    "    \n",
    "    if scores.mean() > score_max:\n",
    "        score_max = scores.mean()\n",
    "        param_best = param         # Param_best is a temoporay variable to store the best parameter \n",
    "        \n",
    "print(\"Highest score : {:.3f} when k = {}\".format(score_max, param_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "separate-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(X_train, X_test, y_train, y_test, classifier):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    \n",
    "    print(\"Train score: {:.2f}\".format(classifier.score(X_train, y_train)))\n",
    "    print(\"Test score: {:.2f}\\n\".format(classifier.score(X_test, y_test)))\n",
    "    print(\"Classification report:\\n{}\".format(classification_report(y_test, pred, zero_division=0)))\n",
    "    print(confusion_matrix(y_test,pred))\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "technical-fever",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 30\n",
      "Train score: 0.49\n",
      "Test score: 0.41\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.34      0.24      0.28        88\n",
      "     neutral       0.43      0.73      0.54       105\n",
      "     postive       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.41       240\n",
      "   macro avg       0.26      0.32      0.27       240\n",
      "weighted avg       0.31      0.41      0.34       240\n",
      "\n",
      "[[21 67  0]\n",
      " [28 77  0]\n",
      " [13 34  0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"k = {}\".format(param_best))\n",
    "knn = KNeighborsClassifier(n_neighbors=param_best)\n",
    "knn = train_test(X_train, X_test, y_train, y_test, knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "controversial-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {}\n",
    "summary[\"k-NNs\"] = round(knn.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-surgeon",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "after-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "minimal-hierarchy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48214286 0.45535714 0.36607143 0.47321429 0.45945946]\n",
      "0.447, 0.042\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(lr, X_train, y_train, cv=5)\n",
    "print(\"{}\\n{:.3f}, {:.3f}\".format(scores, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "selected-cooperative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.99\n",
      "Test score: 0.45\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.23      0.30        88\n",
      "     neutral       0.45      0.83      0.59       105\n",
      "     postive       1.00      0.02      0.04        47\n",
      "\n",
      "    accuracy                           0.45       240\n",
      "   macro avg       0.63      0.36      0.31       240\n",
      "weighted avg       0.55      0.45      0.37       240\n",
      "\n",
      "[[20 68  0]\n",
      " [18 87  0]\n",
      " [ 9 37  1]]\n"
     ]
    }
   ],
   "source": [
    "lr = train_test(X_train, X_test, y_train, y_test, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "color-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"Logistic Regression\"] = round(lr.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-dealer",
   "metadata": {},
   "source": [
    "## Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "humanitarian-superior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "latin-manitoba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46428571 0.48214286 0.39285714 0.51785714 0.48648649]\n",
      "0.469, 0.042\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(mnb, X_train, y_train, cv=5)\n",
    "print(\"{}\\n{:.3f}, {:.3f}\".format(scores, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "underlying-virginia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.95\n",
      "Test score: 0.45\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.25      0.32        88\n",
      "     neutral       0.46      0.82      0.59       105\n",
      "     postive       1.00      0.02      0.04        47\n",
      "\n",
      "    accuracy                           0.45       240\n",
      "   macro avg       0.63      0.36      0.32       240\n",
      "weighted avg       0.55      0.45      0.38       240\n",
      "\n",
      "[[22 66  0]\n",
      " [19 86  0]\n",
      " [10 36  1]]\n"
     ]
    }
   ],
   "source": [
    "mnb = train_test(X_train, X_test, y_train, y_test, mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "rough-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"Multinomial Naive Bayes\"] = round(mnb.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-detail",
   "metadata": {},
   "source": [
    "## Modeling with Linear Support Vector Machines (SVMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "expired-identifier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC(C=1)\n",
    "svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "boolean-screening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 0.43\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.41      0.35      0.38        88\n",
      "     neutral       0.44      0.64      0.52       105\n",
      "     postive       0.36      0.11      0.16        47\n",
      "\n",
      "    accuracy                           0.43       240\n",
      "   macro avg       0.40      0.37      0.36       240\n",
      "weighted avg       0.42      0.43      0.40       240\n",
      "\n",
      "[[31 55  2]\n",
      " [31 67  7]\n",
      " [13 29  5]]\n"
     ]
    }
   ],
   "source": [
    "svm = train_test(X_train, X_test, y_train, y_test, svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "varying-creek",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.01: [0.41071429 0.41071429 0.41071429 0.41964286 0.41441441]\n",
      "0.413, 0.004\n",
      "\n",
      "C = 0.03: [0.41071429 0.41964286 0.41071429 0.41071429 0.41441441]\n",
      "0.413, 0.004\n",
      "\n",
      "C = 0.1: [0.47321429 0.45535714 0.375      0.47321429 0.45945946]\n",
      "0.447, 0.037\n",
      "\n",
      "C = 0.3: [0.4375     0.49107143 0.375      0.49107143 0.45045045]\n",
      "0.449, 0.043\n",
      "\n",
      "C = 1: [0.48214286 0.44642857 0.33035714 0.48214286 0.43243243]\n",
      "0.435, 0.056\n",
      "\n",
      "C = 3: [0.49107143 0.44642857 0.34821429 0.46428571 0.41441441]\n",
      "0.433, 0.049\n",
      "\n",
      "C = 10: [0.48214286 0.42857143 0.375      0.4375     0.41441441]\n",
      "0.428, 0.035\n",
      "\n",
      "Highest score : 0.449 when C = 0.3\n"
     ]
    }
   ],
   "source": [
    "score_max = 0\n",
    "for param in [0.01, 0.03, 0.1, 0.3, 1, 3, 10]:\n",
    "    model = LinearSVC(C=param)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    print(\"C = {}: {}\\n{:.3f}, {:.3f}\\n\".format(param, scores, scores.mean(), scores.std()))\n",
    "    \n",
    "    if scores.mean() > score_max:\n",
    "        score_max = scores.mean()\n",
    "        param_best = param\n",
    "        \n",
    "print(\"Highest score : {:.3f} when C = {}\".format(score_max, param_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "abstract-satisfaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.3\n",
      "Train score: 1.00\n",
      "Test score: 0.45\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.31      0.36        88\n",
      "     neutral       0.45      0.75      0.56       105\n",
      "     postive       0.40      0.04      0.08        47\n",
      "\n",
      "    accuracy                           0.45       240\n",
      "   macro avg       0.43      0.37      0.34       240\n",
      "weighted avg       0.44      0.45      0.40       240\n",
      "\n",
      "[[27 61  0]\n",
      " [23 79  3]\n",
      " [10 35  2]]\n"
     ]
    }
   ],
   "source": [
    "print(\"C = {}\".format(param_best))\n",
    "svm = LinearSVC(C=param_best)\n",
    "svm = train_test(X_train, X_test, y_train, y_test, svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "adapted-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"Linear SVMs\"] = round(svm.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-playing",
   "metadata": {},
   "source": [
    "## Modeling with Kernelized Support Vector Machines (KSVMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "sized-fellowship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksvm = SVC(C=1, kernel=\"rbf\", gamma=\"scale\")\n",
    "ksvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "white-petite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 0.45\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.05      0.09        88\n",
      "     neutral       0.45      1.00      0.62       105\n",
      "     postive       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.45       240\n",
      "   macro avg       0.37      0.35      0.23       240\n",
      "weighted avg       0.44      0.45      0.30       240\n",
      "\n",
      "[[  4  84   0]\n",
      " [  0 105   0]\n",
      " [  2  45   0]]\n"
     ]
    }
   ],
   "source": [
    "ksvm = train_test(X_train, X_test, y_train, y_test, ksvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "accompanied-cuisine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.01: [0.41071429 0.41071429 0.41071429 0.41964286 0.41441441]\n",
      "0.413, 0.004\n",
      "\n",
      "C = 0.03: [0.41071429 0.41071429 0.41071429 0.41964286 0.41441441]\n",
      "0.413, 0.004\n",
      "\n",
      "C = 0.1: [0.41071429 0.41071429 0.41071429 0.41964286 0.41441441]\n",
      "0.413, 0.004\n",
      "\n",
      "C = 0.3: [0.41071429 0.41071429 0.41071429 0.41964286 0.41441441]\n",
      "0.413, 0.004\n",
      "\n",
      "C = 1: [0.41071429 0.4375     0.41964286 0.40178571 0.42342342]\n",
      "0.419, 0.012\n",
      "\n",
      "C = 3: [0.47321429 0.46428571 0.375      0.48214286 0.45045045]\n",
      "0.449, 0.038\n",
      "\n",
      "C = 10: [0.47321429 0.46428571 0.375      0.48214286 0.45045045]\n",
      "0.449, 0.038\n",
      "\n",
      "Highest score : 0.449 when C = 3\n"
     ]
    }
   ],
   "source": [
    "score_max = 0\n",
    "for param in [0.01, 0.03, 0.1, 0.3, 1, 3, 10]:\n",
    "    model = SVC(C=param, kernel=\"rbf\", gamma=\"scale\")\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    print(\"C = {}: {}\\n{:.3f}, {:.3f}\\n\".format(param, scores, scores.mean(), scores.std()))\n",
    "    \n",
    "    if scores.mean() > score_max:\n",
    "        score_max = scores.mean()\n",
    "        param_best = param\n",
    "        \n",
    "print(\"Highest score : {:.3f} when C = {}\".format(score_max, param_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ideal-breeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 3\n",
      "Train score: 1.00\n",
      "Test score: 0.46\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.24      0.31        88\n",
      "     neutral       0.46      0.84      0.59       105\n",
      "     postive       1.00      0.02      0.04        47\n",
      "\n",
      "    accuracy                           0.46       240\n",
      "   macro avg       0.64      0.37      0.32       240\n",
      "weighted avg       0.56      0.46      0.38       240\n",
      "\n",
      "[[21 67  0]\n",
      " [17 88  0]\n",
      " [ 9 37  1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"C = {}\".format(param_best))\n",
    "ksvm = SVC(C=param_best)\n",
    "ksvm = train_test(X_train, X_test, y_train, y_test, ksvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "polished-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"Kernelized SVMs\"] = round(ksvm.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-oxide",
   "metadata": {},
   "source": [
    "## Modeling with Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "strategic-married",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(10,), random_state=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(10, ), activation=\"relu\", random_state=0)\n",
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ready-tender",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 0.44\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.39      0.40        88\n",
      "     neutral       0.47      0.62      0.53       105\n",
      "     postive       0.35      0.13      0.19        47\n",
      "\n",
      "    accuracy                           0.44       240\n",
      "   macro avg       0.41      0.38      0.37       240\n",
      "weighted avg       0.42      0.44      0.41       240\n",
      "\n",
      "[[34 49  5]\n",
      " [34 65  6]\n",
      " [16 25  6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp = train_test(X_train, X_test, y_train, y_test, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "tough-yorkshire",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_layer_size = 10: [0.5        0.47321429 0.30357143 0.42857143 0.45045045]\n",
      "0.431, 0.068\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_layer_size = 30: [0.44642857 0.44642857 0.32142857 0.41964286 0.46846847]\n",
      "0.420, 0.052\n",
      "\n",
      "hidden_layer_size = 100: [0.46428571 0.45535714 0.33928571 0.41964286 0.45045045]\n",
      "0.426, 0.046\n",
      "\n",
      "Highest score : 0.431 when hidden_layer_sizes = 10\n"
     ]
    }
   ],
   "source": [
    "score_max = 0\n",
    "for param in [10, 30, 100]:\n",
    "    model = MLPClassifier(hidden_layer_sizes=(param, ), activation=\"relu\", random_state=0)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    print(\"hidden_layer_size = {}: {}\\n{:.3f}, {:.3f}\\n\".format(param, scores, scores.mean(), scores.std()))\n",
    "    \n",
    "    if scores.mean() > score_max:\n",
    "        score_max = scores.mean()\n",
    "        param_best = param\n",
    "        \n",
    "print(\"Highest score : {:.3f} when hidden_layer_sizes = {}\".format(score_max, param_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "north-sheriff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_layer_size = 10\n",
      "Train score: 1.00\n",
      "Test score: 0.44\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.39      0.40        88\n",
      "     neutral       0.47      0.62      0.53       105\n",
      "     postive       0.35      0.13      0.19        47\n",
      "\n",
      "    accuracy                           0.44       240\n",
      "   macro avg       0.41      0.38      0.37       240\n",
      "weighted avg       0.42      0.44      0.41       240\n",
      "\n",
      "[[34 49  5]\n",
      " [34 65  6]\n",
      " [16 25  6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"hidden_layer_size = {}\".format(param_best))\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(param_best, ), random_state=0)\n",
    "mlp = train_test(X_train, X_test, y_train, y_test, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "awful-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"Neural Networks\"] = round(mlp.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-kidney",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "widespread-catch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "meaningful-comment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33928571 0.41071429 0.38392857 0.44642857 0.42342342]\n",
      "0.401, 0.037\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(dt, X_train, y_train, cv=5)\n",
    "print(\"{}\\n{:.3f}, {:.3f}\".format(scores, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "german-blowing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 0.40\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.28      0.33        88\n",
      "     neutral       0.43      0.61      0.50       105\n",
      "     postive       0.22      0.13      0.16        47\n",
      "\n",
      "    accuracy                           0.40       240\n",
      "   macro avg       0.35      0.34      0.33       240\n",
      "weighted avg       0.38      0.40      0.37       240\n",
      "\n",
      "[[25 55  8]\n",
      " [28 64 13]\n",
      " [10 31  6]]\n"
     ]
    }
   ],
   "source": [
    "dt = train_test(X_train, X_test, y_train, y_test, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "supported-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"Decision Tree\"] = round(dt.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-diagnosis",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "stock-software",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 1: [0.41071429 0.41071429 0.41071429 0.41964286 0.41441441]\n",
      "0.413, 0.004\n",
      "\n",
      "C = 3: [0.41071429 0.41071429 0.41071429 0.41964286 0.41441441]\n",
      "0.413, 0.004\n",
      "\n",
      "C = 10: [0.41071429 0.42857143 0.41964286 0.41071429 0.42342342]\n",
      "0.419, 0.007\n",
      "\n",
      "C = 12: [0.42857143 0.41964286 0.41964286 0.41071429 0.42342342]\n",
      "0.420, 0.006\n",
      "\n",
      "C = 14: [0.39285714 0.42857143 0.41964286 0.4375     0.42342342]\n",
      "0.420, 0.015\n",
      "\n",
      "C = 16: [0.42857143 0.45535714 0.42857143 0.41964286 0.43243243]\n",
      "0.433, 0.012\n",
      "\n",
      "C = 18: [0.4375     0.40178571 0.42857143 0.44642857 0.43243243]\n",
      "0.429, 0.015\n",
      "\n",
      "C = 20: [0.41964286 0.42857143 0.39285714 0.4375     0.43243243]\n",
      "0.422, 0.016\n",
      "\n",
      "Highest score : 0.433 when C = 16\n"
     ]
    }
   ],
   "source": [
    "score_max = 0\n",
    "for param in [1, 3, 10, 12, 14, 16, 18, 20]:\n",
    "    model = RandomForestClassifier(max_depth=param)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    print(\"C = {}: {}\\n{:.3f}, {:.3f}\\n\".format(param, scores, scores.mean(), scores.std()))\n",
    "    \n",
    "    if scores.mean() > score_max:\n",
    "        score_max = scores.mean()\n",
    "        param_best = param\n",
    "        \n",
    "print(\"Highest score : {:.3f} when C = {}\".format(score_max, param_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "established-track",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 16\n",
      "Train score: 0.60\n",
      "Test score: 0.46\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.09      0.16        88\n",
      "     neutral       0.45      0.97      0.62       105\n",
      "     postive       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.46       240\n",
      "   macro avg       0.34      0.35      0.26       240\n",
      "weighted avg       0.41      0.46      0.33       240\n",
      "\n",
      "[[  8  80   0]\n",
      " [  3 102   0]\n",
      " [  3  44   0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"C = {}\".format(param_best))\n",
    "rf = RandomForestClassifier(max_depth=param_best)\n",
    "rf = train_test(X_train, X_test, y_train, y_test, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "convinced-beast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=16, n_estimators=10)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rf = RandomForestClassifier(max_depth = 16, n_estimators=10)\n",
    "# rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "dynamic-freedom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45535714 0.41964286 0.41071429 0.42857143 0.40540541]\n",
      "0.424, 0.018\n"
     ]
    }
   ],
   "source": [
    "# scores = cross_val_score(rf, X_train, y_train, cv=5)\n",
    "# print(\"{}\\n{:.3f}, {:.3f}\".format(scores, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "unique-calgary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.61\n",
      "Test score: 0.42\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.41      0.14      0.21        88\n",
      "     neutral       0.43      0.85      0.57       105\n",
      "     postive       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.42       240\n",
      "   macro avg       0.28      0.33      0.26       240\n",
      "weighted avg       0.34      0.42      0.32       240\n",
      "\n",
      "[[12 74  2]\n",
      " [14 89  2]\n",
      " [ 3 44  0]]\n"
     ]
    }
   ],
   "source": [
    "# rf = train_test(X_train, X_test, y_train, y_test, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "altered-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"Random Forest\"] = round(rf.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "stainless-mediterranean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.45,\n",
       " 'Multinomial Naive Bayes': 0.454,\n",
       " 'Linear SVMs': 0.45,\n",
       " 'Kernelized SVMs': 0.458,\n",
       " 'Neural Networks': 0.438,\n",
       " 'k-NNs': 0.408,\n",
       " 'Decision Tree': 0.396,\n",
       " 'Random Forest': 0.421}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-heading",
   "metadata": {},
   "source": [
    "## New sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "spread-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"This is amazing, climate change initiatives have created so many jobs!\"\n",
    "text2 = \"I hate the bad idea of hotter temperatures and the horrible fact that ice caps are melting\"\n",
    "text3 = \"Ice caps are melting faster each year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fifth-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_texts = [text1, text2, text3]\n",
    "X_new = vectorizer.transform(new_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "coordinate-casino",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'neutral', 'neutral'], dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "coordinate-malaysia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'negative', 'neutral'], dtype='<U8')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "invisible-equity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'negative', 'neutral'], dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "personal-hammer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'negative', 'neutral'], dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksvm.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dimensional-tribute",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['postive', 'negative', 'neutral'], dtype='<U8')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "compliant-thesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['postive', 'negative', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "vietnamese-boards",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'negative', 'neutral'], dtype=object)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-delight",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-jimmy",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ordered-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates([\"sentence\"], keep=\"first\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "personalized-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string \n",
    "\n",
    "global_stopwords = stopwords.words(\"english\")\n",
    "local_stopwords = [c for c in string.punctuation] +\\\n",
    "                  ['’', '``', '…', '...', \"''\", '‘', '“', '”', \"'m\", \"'re\", \"'s\", \"'ve\", 'amp', 'https', \"n't\", 'rt', \n",
    "                   'covid19', 'coronavirus', 'covid19…', 'covid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "historical-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf=True, norm=\"l2\", stop_words=global_stopwords+local_stopwords, max_df=0.7)\n",
    "X = vectorizer.fit_transform(df.sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "spatial-thailand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799, 4739)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "thermal-three",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=10, random_state=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10\n",
    "kmeans = KMeans(n_clusters = k, random_state=0)\n",
    "kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "binding-andrew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 939 ms, sys: 7.21 ms, total: 946 ms\n",
      "Wall time: 253 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=10, random_state=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "under-alberta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.00215668,\n",
       "        0.0016607 ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.0088392 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.00328377, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.00782006, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.00562691, ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "divine-probe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4739)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "iraqi-karaoke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 4, 6, 3, 0, 0, 2, 0, 3, 1, 6, 3, 1, 5, 4, 3, 0, 7, 3, 1, 8, 7,\n",
       "       0, 8, 5, 6, 0, 3, 7, 3, 9, 4, 3, 9, 7, 1, 0, 9, 0, 6, 2, 3, 0, 3,\n",
       "       0, 0, 7, 3, 5, 9, 3, 6, 3, 6, 0, 3, 6, 3, 4, 4, 8, 4, 2, 3, 0, 2,\n",
       "       2, 0, 6, 1, 0, 0, 6, 3, 8, 6, 8, 6, 0, 6, 1, 1, 3, 1, 4, 5, 0, 3,\n",
       "       2, 9, 8, 2, 8, 1, 3, 4, 7, 2, 6, 4, 4, 4, 2, 7, 3, 5, 9, 1, 6, 2,\n",
       "       2, 5, 0, 8, 3, 5, 8, 3, 0, 0, 7, 1, 9, 8, 5, 3, 0, 6, 7, 9, 0, 4,\n",
       "       1, 1, 2, 8, 0, 0, 0, 9, 0, 3, 0, 1, 4, 8, 0, 9, 6, 4, 7, 3, 5, 4,\n",
       "       0, 0, 6, 7, 1, 8, 7, 0, 7, 2, 1, 7, 3, 0, 5, 0, 2, 6, 9, 8, 4, 5,\n",
       "       5, 4, 7, 8, 0, 0, 3, 3, 3, 2, 3, 1, 1, 8, 6, 2, 1, 0, 9, 9, 4, 3,\n",
       "       8, 1, 2, 4, 1, 1, 7, 3, 7, 6, 0, 0, 7, 0, 4, 4, 6, 2, 8, 3, 3, 0,\n",
       "       3, 0, 0, 9, 0, 7, 3, 3, 3, 0, 5, 4, 2, 1, 3, 2, 7, 0, 3, 6, 7, 0,\n",
       "       0, 6, 6, 5, 6, 4, 4, 9, 3, 4, 9, 4, 4, 2, 4, 4, 2, 0, 5, 9, 0, 2,\n",
       "       7, 4, 6, 3, 6, 3, 5, 7, 0, 0, 7, 3, 4, 2, 6, 6, 0, 3, 7, 4, 6, 2,\n",
       "       9, 6, 6, 4, 0, 3, 5, 6, 0, 7, 0, 0, 3, 1, 4, 2, 3, 7, 5, 0, 4, 6,\n",
       "       8, 9, 8, 3, 9, 0, 1, 2, 4, 7, 9, 6, 3, 7, 0, 1, 9, 2, 5, 3, 8, 3,\n",
       "       7, 1, 4, 4, 7, 5, 1, 7, 1, 3, 0, 1, 2, 9, 0, 4, 6, 4, 3, 4, 8, 2,\n",
       "       3, 4, 3, 3, 0, 2, 3, 6, 3, 9, 9, 0, 5, 1, 0, 1, 3, 1, 0, 3, 3, 6,\n",
       "       3, 3, 0, 8, 3, 3, 0, 0, 0, 1, 1, 3, 7, 0, 5, 2, 3, 3, 6, 6, 1, 3,\n",
       "       1, 5, 2, 0, 7, 0, 4, 3, 4, 8, 3, 6, 7, 3, 1, 0, 0, 0, 7, 4, 9, 9,\n",
       "       9, 2, 0, 9, 3, 6, 6, 0, 0, 3, 0, 0, 0, 4, 3, 7, 3, 0, 6, 5, 9, 1,\n",
       "       3, 8, 3, 0, 7, 1, 0, 6, 0, 4, 2, 7, 3, 7, 3, 4, 2, 6, 5, 4, 1, 3,\n",
       "       6, 4, 0, 2, 0, 2, 2, 2, 7, 8, 0, 4, 0, 0, 6, 4, 8, 6, 0, 2, 0, 4,\n",
       "       4, 0, 7, 1, 6, 0, 3, 9, 9, 4, 5, 3, 3, 6, 8, 6, 0, 4, 7, 3, 0, 7,\n",
       "       3, 4, 3, 3, 3, 5, 4, 4, 0, 4, 8, 3, 6, 1, 3, 6, 4, 0, 4, 5, 3, 0,\n",
       "       8, 0, 8, 0, 9, 4, 3, 0, 0, 4, 3, 0, 6, 3, 5, 5, 2, 0, 2, 7, 4, 5,\n",
       "       8, 3, 3, 8, 1, 0, 3, 5, 6, 3, 7, 3, 0, 4, 4, 3, 3, 0, 0, 3, 4, 3,\n",
       "       0, 5, 6, 7, 7, 6, 5, 1, 9, 4, 8, 1, 0, 4, 0, 5, 3, 9, 0, 9, 5, 0,\n",
       "       4, 0, 2, 2, 7, 9, 4, 0, 1, 0, 1, 2, 0, 7, 0, 5, 5, 2, 7, 3, 2, 6,\n",
       "       0, 9, 4, 4, 2, 0, 1, 0, 7, 5, 8, 9, 2, 3, 3, 3, 3, 0, 9, 3, 9, 2,\n",
       "       3, 3, 3, 0, 3, 1, 5, 0, 2, 0, 0, 2, 1, 9, 3, 2, 3, 4, 0, 3, 0, 7,\n",
       "       0, 8, 9, 1, 1, 7, 1, 5, 7, 7, 4, 9, 2, 4, 8, 1, 3, 6, 2, 2, 9, 4,\n",
       "       7, 3, 4, 9, 0, 5, 3, 0, 0, 5, 0, 0, 4, 3, 1, 7, 3, 9, 4, 7, 8, 4,\n",
       "       9, 3, 6, 3, 0, 3, 6, 8, 3, 0, 9, 0, 3, 6, 3, 7, 0, 6, 8, 3, 8, 3,\n",
       "       3, 0, 4, 5, 3, 9, 3, 0, 6, 0, 0, 3, 6, 6, 8, 4, 3, 0, 4, 3, 5, 9,\n",
       "       0, 2, 5, 6, 1, 7, 0, 6, 2, 0, 6, 0, 3, 3, 3, 4, 3, 6, 1, 0, 9, 9,\n",
       "       6, 2, 8, 1, 6, 6, 7, 2, 6, 1, 0, 8, 6, 0, 9, 1, 7, 0, 4, 3, 3, 1,\n",
       "       1, 6, 0, 4, 9, 2, 9], dtype=int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "underlying-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cluster\"] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "included-still",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It also increases carbon dioxide emissions whi...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We can already see this happening.\\t</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The ecological disaster is a consequence of no...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We may be dealing with an issue with a level o...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Preventable chronic diseases are Australiaâ€™s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>Copenhagen and Amsterdam are known for their a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>Nine out of 12 months were warmer than average...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>Over recent decades temperatures in the most n...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>In 2019 the investment advisor Mercer modelled...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>Freshwater from melting of ice sheets and glac...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>799 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  cluster\n",
       "0    It also increases carbon dioxide emissions whi...        8\n",
       "1                 We can already see this happening.\\t        4\n",
       "2    The ecological disaster is a consequence of no...        6\n",
       "3    We may be dealing with an issue with a level o...        3\n",
       "4    Preventable chronic diseases are Australiaâ€™s...        0\n",
       "..                                                 ...      ...\n",
       "794  Copenhagen and Amsterdam are known for their a...        0\n",
       "795  Nine out of 12 months were warmer than average...        4\n",
       "796  Over recent decades temperatures in the most n...        9\n",
       "797  In 2019 the investment advisor Mercer modelled...        2\n",
       "798  Freshwater from melting of ice sheets and glac...        9\n",
       "\n",
       "[799 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"sentence\", \"cluster\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "medical-corps",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    154\n",
       "3    145\n",
       "4     88\n",
       "6     77\n",
       "1     63\n",
       "7     63\n",
       "2     62\n",
       "9     56\n",
       "5     46\n",
       "8     45\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cluster.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "several-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df.cluster.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "local-blake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>One day after the EUâ€™s announcement the US H...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>This would bring total deforestation to 40 per...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>All parties and the media now talk about it in...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>The one with the highest current emissions is ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>And I think thatâ€™s something thatâ€™s good f...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>In light of Brexit and the United States elect...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>To find out we cross-referenced what people sa...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>They can tell us very little about interaction...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>Power stations around the world will continue ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>The price band will be implemented at auction ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  cluster\n",
       "60   One day after the EUâ€™s announcement the US H...        8\n",
       "23   This would bring total deforestation to 40 per...        8\n",
       "528  All parties and the media now talk about it in...        8\n",
       "328  The one with the highest current emissions is ...        8\n",
       "350  And I think thatâ€™s something thatâ€™s good f...        8\n",
       "724  In light of Brexit and the United States elect...        8\n",
       "308  To find out we cross-referenced what people sa...        8\n",
       "626  They can tell us very little about interaction...        8\n",
       "582  Power stations around the world will continue ...        8\n",
       "553  The price band will be implemented at auction ...        8"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.cluster == counts.idxmin()].sample(10, random_state=1)[[\"sentence\", \"cluster\"]] #largest cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "traditional-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "df[\"words\"] = df.sentence.apply(lambda x: nltk.word_tokenize(x))\n",
    "df[\"tagged_words\"] = df.words.apply(lambda x: nltk.pos_tag(x))\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def get_counter(dataframe, stopwords=[]):\n",
    "    counter = Counter()\n",
    "    \n",
    "    for l in dataframe.tagged_words:\n",
    "        word_set = set()\n",
    "\n",
    "        for t in l:\n",
    "            word = t[0].lower()\n",
    "            tag = t[1]\n",
    "\n",
    "            if word not in stopwords:\n",
    "                word_set.add(word)\n",
    "            \n",
    "        counter.update(word_set)\n",
    "        \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "particular-works",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('example', 12),\n",
       " ('good', 9),\n",
       " ('may', 8),\n",
       " ('also', 7),\n",
       " ('much', 6),\n",
       " ('use', 6),\n",
       " ('areas', 5),\n",
       " ('problem', 5),\n",
       " ('view', 5),\n",
       " ('world', 5),\n",
       " ('provide', 5),\n",
       " ('federal', 4),\n",
       " ('australia', 4),\n",
       " ('know', 4),\n",
       " ('whether', 4),\n",
       " ('sea', 4),\n",
       " ('summer', 4),\n",
       " ('many', 4),\n",
       " ('could', 4),\n",
       " ('means', 4),\n",
       " ('canâ€™t', 4),\n",
       " ('people', 4),\n",
       " ('year', 4),\n",
       " ('like', 4),\n",
       " ('would', 4),\n",
       " ('made', 4),\n",
       " ('health', 3),\n",
       " ('conditions', 3),\n",
       " ('quickly', 3),\n",
       " ('since', 3)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_max = get_counter(df[df.cluster == counts.idxmax()], global_stopwords+local_stopwords)\n",
    "counter_max.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "passing-marijuana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('us', 16),\n",
       " ('per', 14),\n",
       " ('carbon', 11),\n",
       " ('dioxide', 10),\n",
       " ('year', 9),\n",
       " ('emissions', 8),\n",
       " ('coâ‚‚', 7),\n",
       " ('climate', 6),\n",
       " ('one', 5),\n",
       " ('world', 5),\n",
       " ('current', 4),\n",
       " ('australia', 4),\n",
       " ('would', 4),\n",
       " ('average', 4),\n",
       " ('new', 4),\n",
       " ('times', 4),\n",
       " ('plants', 4),\n",
       " ('change', 3),\n",
       " ('total', 3),\n",
       " ('levels', 3),\n",
       " ('global', 3),\n",
       " ('thatâ€™s', 3),\n",
       " ('last', 3),\n",
       " ('planet', 3),\n",
       " ('amount', 3),\n",
       " ('years', 3),\n",
       " ('set', 3),\n",
       " ('capita', 2),\n",
       " ('highest', 2),\n",
       " ('case', 2)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_min = get_counter(df[df.cluster == counts.idxmin()], global_stopwords+local_stopwords)\n",
    "counter_min.most_common(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-graduation",
   "metadata": {},
   "source": [
    "### LDA Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "instant-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_stopwords = stopwords.words(\"english\")\n",
    "local_stopwords = [c for c in string.punctuation] +\\\n",
    "                  ['’', '``', '…', '...', \"''\", '‘', '“', '”', \"'m\", \"'re\", \"'s\", \"'ve\", 'amp', 'https', \"n't\", 'rt', \n",
    "                   'covid19', 'coronavirus', 'covid19…', 'covid', 'co', 'cases']\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf=True, norm=\"l2\", stop_words=global_stopwords+local_stopwords, max_df=0.7)\n",
    "X = vectorizer.fit_transform(df.sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "described-american",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "num_topics = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "solved-least",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=3, random_state=0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "lda = LDA(n_components=num_topics, random_state=0)     # LDA uses randomness to get a probability distribution\n",
    "lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "arbitrary-advocate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.16 s, sys: 0 ns, total: 1.16 s\n",
      "Wall time: 1.16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=3, random_state=0)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time lda.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "running-processor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.64727959, 0.33456103, 1.20558892, ..., 0.33406022, 0.33424728,\n",
       "        0.33399295],\n",
       "       [0.33462155, 0.33485533, 0.3350449 , ..., 0.53870723, 0.66342964,\n",
       "        0.58769206],\n",
       "       [0.33444263, 0.68248625, 0.63701632, ..., 0.33411016, 0.33445238,\n",
       "        0.33406284]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "hispanic-replacement",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.64727959, 0.33456103, 1.20558892, ..., 0.33406022, 0.33424728,\n",
       "        0.33399295],\n",
       "       [0.33462155, 0.33485533, 0.3350449 , ..., 0.53870723, 0.66342964,\n",
       "        0.58769206],\n",
       "       [0.33444263, 0.68248625, 0.63701632, ..., 0.33411016, 0.33445238,\n",
       "        0.33406284]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "accessory-jungle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 4737)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "effective-japanese",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def show_topics(model, feature_names, num_top_words):\n",
    "    for topic_idx, topic_scores in enumerate(model.components_):\n",
    "        print(\"***Topic {}:\".format(topic_idx))\n",
    "        print(\" + \".join([\"{:.2f} * {}\".format(topic_scores[i], feature_names[i]) for i in topic_scores.argsort()[::-1][:num_top_words]]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "stretch-macintosh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Topic 0:\n",
      "8.16 * climate + 5.44 * change + 4.74 * carbon + 4.12 * new + 3.73 * also + 3.11 * energy + 2.96 * need + 2.88 * people + 2.84 * australia + 2.84 * already\n",
      "\n",
      "***Topic 1:\n",
      "6.54 * climate + 5.33 * change + 3.28 * many + 3.23 * likely + 3.17 * one + 3.11 * use + 2.97 * growth + 2.92 * already + 2.65 * term + 2.62 * others\n",
      "\n",
      "***Topic 2:\n",
      "4.98 * climate + 3.91 * also + 3.86 * change + 3.56 * ice + 3.49 * may + 3.48 * one + 3.31 * year + 3.17 * people + 3.15 * emissions + 3.01 * carbon\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "show_topics(lda, vectorizer.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "popular-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "exotic-footage",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el3301401153889646883465307712\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el3301401153889646883465307712_data = {\"mdsDat\": {\"x\": [-0.0256729134892022, 0.01930877394830558, 0.006364139540896638], \"y\": [-0.0072838935494709085, -0.01802712047058125, 0.025311014020052147], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [35.605494900647095, 33.4891327882307, 30.905372311122214]}, \"tinfo\": {\"Term\": [\"growth\", \"provide\", \"others\", \"already\", \"urban\", \"likely\", \"term\", \"warmer\", \"can\\u00e2\", \"here\\u00e2\", \"happening\", \"world\\u00e2\", \"paris\", \"rainfall\", \"seen\", \"see\", \"power\", \"five\", \"dioxide\", \"education\", \"adaptation\", \"carbon\", \"forests\", \"scientific\", \"needs\", \"that\\u00e2\", \"focused\", \"take\", \"fossil\", \"livestock\", \"urban\", \"really\", \"enough\", \"produce\", \"adaptation\", \"addressing\", \"limited\", \"paris\", \"university\", \"fuels\", \"published\", \"benefit\", \"agriculture\", \"financial\", \"consume\", \"islands\", \"scientific\", \"studies\", \"circulation\", \"sustainable\", \"gases\", \"beep\", \"200\", \"meltwater\", \"fall\", \"modelling\", \"aren\\u00e2\", \"ask\", \"sheet\", \"prepared\", \"mitigation\", \"hope\", \"yet\", \"pollution\", \"fossil\", \"carbon\", \"human\", \"new\", \"climate\", \"large\", \"help\", \"become\", \"energy\", \"part\", \"change\", \"also\", \"need\", \"already\", \"evidence\", \"levels\", \"us\", \"australia\", \"high\", \"science\", \"sea\", \"people\", \"around\", \"natural\", \"year\", \"global\", \"emissions\", \"many\", \"would\", \"world\", \"ice\", \"warmer\", \"education\", \"seen\", \"livestock\", \"needs\", \"rainfall\", \"present\", \"that\\u00e2\", \"end\", \"farmers\", \"bad\", \"focused\", \"dioxide\", \"zero\", \"takes\", \"data\", \"hit\", \"cannot\", \"effect\", \"melting\", \"argues\", \"expect\", \"convention\", \"expand\", \"december\", \"intelligence\", \"mass\", \"normal\", \"cities\", \"thrive\", \"view\", \"president\", \"power\", \"second\", \"mean\", \"causes\", \"federal\", \"state\", \"biodiversity\", \"may\", \"come\", \"often\", \"last\", \"ice\", \"whether\", \"also\", \"water\", \"one\", \"year\", \"level\", \"air\", \"temperatures\", \"emissions\", \"time\", \"climate\", \"people\", \"change\", \"years\", \"carbon\", \"global\", \"new\", \"australia\", \"research\", \"warming\", \"us\", \"countries\", \"world\", \"provide\", \"growth\", \"others\", \"here\\u00e2\", \"short\", \"focus\", \"happening\", \"can\\u00e2\", \"forgotten\", \"treatment\", \"innovation\", \"aegypti\", \"helping\", \"contain\", \"see\", \"term\", \"structures\", \"companies\", \"plans\", \"world\\u00e2\", \"poor\", \"protect\", \"fires\", \"writers\", \"occur\", \"nsw\", \"amusing\", \"small\", \"supported\", \"16\", \"five\", \"likely\", \"forests\", \"affected\", \"threat\", \"least\", \"create\", \"use\", \"conditions\", \"many\", \"already\", \"less\", \"change\", \"climate\", \"problems\", \"one\", \"even\", \"take\", \"well\", \"countries\", \"global\", \"across\", \"current\", \"people\", \"warming\", \"time\", \"emissions\", \"much\"], \"Freq\": [1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0469760390678389, 0.6940399354044081, 0.6794420625154729, 0.6747167856895733, 0.8166734664468767, 0.6797381895552917, 0.6537381643771727, 0.9979970731320457, 0.7422887100045618, 0.6924234559566441, 0.6979638767818119, 0.569719410672753, 0.5674894456209538, 0.7859589564784475, 0.5469859347727981, 0.5673781943405583, 1.0153877323752152, 0.6545458328354913, 0.545383156208463, 0.5210176935094473, 0.5184330837193233, 0.512326966355251, 0.5123269377345832, 0.5009144597317764, 0.6379941927861231, 0.4946859739503008, 0.49340686785942967, 0.8004590552369595, 0.4829118001881166, 0.47887247492506263, 0.9047513477534634, 0.713879381738952, 0.7728904692616386, 0.7479675136929261, 0.9317102893880361, 1.8297072586698313, 1.0685075518746256, 1.5888385970088228, 3.1502016106820743, 0.83967918595716, 0.8986454146120847, 0.8805879655321878, 1.199440206923182, 0.8167736293231359, 2.097879046904588, 1.4396079765572565, 1.1413556817642938, 1.0944049968012985, 0.9071842297684641, 0.8463426995158327, 1.0836021910590503, 1.094839934718463, 0.9010497300166961, 0.9610312120395503, 1.0142659592708292, 1.1099588642621934, 0.8595813208977598, 0.9308439946802697, 1.0256472581052547, 0.9815783274408939, 0.9653062413485488, 0.9412036735125402, 0.9000982679349306, 0.8912638086206217, 0.8909277335750042, 0.906828755422924, 0.675177051405525, 0.7530061692555666, 0.6279914640234602, 0.713267376912433, 0.8398814798211516, 0.5697022180051448, 0.7101807759022016, 0.5321193773935746, 0.5300963353667868, 0.5306608209283442, 0.7304754461151136, 0.8591320727636984, 0.4715633346375786, 0.46066381277622614, 0.8019388570236862, 0.4588796538808255, 0.45613562152650666, 0.6437323211354743, 0.44983390333020296, 0.4482425971401699, 0.44801291745649957, 0.44008632853131563, 0.4389333887808969, 0.437193814638035, 0.43209704209099137, 0.4312731224901794, 0.4246362462144505, 0.8516814801925445, 0.4229519754204171, 0.7462031870395789, 0.5483281957473092, 0.9790556306361415, 0.6000089377872838, 0.8030426406612284, 0.6510120456937712, 0.6312305198820891, 0.7350797723036819, 0.6208786572478217, 1.3012771517209818, 0.8300769956897008, 0.7540972493998325, 0.836170886224496, 1.3267865613176335, 0.7085254309287792, 1.4581687913876216, 0.999322639032477, 1.2967018734785098, 1.2343494290620798, 0.8284051803519646, 0.7690670148549386, 0.8746312670012379, 1.1751571493195658, 1.0506101348609693, 1.855862408407977, 1.1825427139625262, 1.4402244240046802, 0.9436431419348745, 1.1230843107275439, 1.008971598968686, 0.9533282932168109, 0.9104356014142925, 0.8521190551241976, 0.903704186190098, 0.8658375272993795, 0.8450820521316207, 0.840986432247944, 0.916387289023829, 1.0589439968058567, 0.9355954166906872, 0.681431737418077, 0.5100268250902836, 0.5004204492866065, 0.7838861099465352, 0.8511776226315546, 0.47451908776706153, 0.4722191910051995, 0.4721414602841287, 0.4735893271552655, 0.46775624434338253, 0.46237351052841286, 0.7021413961570799, 0.9455807801160754, 0.4538286781412214, 0.4537615130022665, 0.4454944880372879, 0.7972887846445235, 0.43343986944107066, 0.5598095426321378, 0.5497071018644645, 0.4188071991080873, 0.4161173792895451, 0.4157647322931623, 0.4035974385419811, 0.5054522876789636, 0.3894507884235381, 0.3876110100574818, 0.7927894374545046, 1.1513650123651453, 0.8146598716049428, 0.5135198141376163, 0.6009273050982112, 0.8485247303326755, 0.5997196438874972, 1.1071381480003655, 0.7627417235253721, 1.1695440184962287, 1.0401935021215805, 0.7572341370249119, 1.8993330122782603, 2.3310743489518138, 0.5779615319363831, 1.1308800453786254, 0.7207808333533612, 0.7128847519121769, 0.7096827125311477, 0.8697659484864473, 0.8996335368672342, 0.6487138053221372, 0.6691186573773299, 0.8864816210959017, 0.8160126794789868, 0.7975395172173639, 0.8469955322114294, 0.7662420423445302], \"Total\": [1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.3295505915911083, 0.938227908124399, 0.9232449011518917, 0.9212216588238895, 1.1153737829221873, 0.9324410472362302, 0.9041733448658731, 1.382214046627902, 1.036783380730975, 0.9781666892687886, 0.989357940272007, 0.8136304489236104, 0.8113192851445103, 1.1290070013843647, 0.7947303035182434, 0.8260665566481088, 1.4828348803943185, 0.9565244795317942, 0.7987507448924646, 0.7647058515215887, 0.7623604362985757, 0.7574958436115985, 0.7574958419483766, 0.7447336078722809, 0.950319717195264, 0.7385640384994973, 0.737389859545947, 1.2039195412675123, 0.7268204701894959, 0.7227522048392456, 1.397740662356889, 1.0932430616297895, 1.1975370406728807, 1.1635779059533744, 1.5118985503634164, 3.3998868676796, 1.821101608626668, 3.0293055225174665, 7.337138368041865, 1.400960557213503, 1.533388773579352, 1.5071190802185732, 2.3041186116255217, 1.3644474964887954, 5.437436483187529, 3.5071977345299707, 2.4097257439917685, 2.2817008040775857, 1.653578806337509, 1.460516044584469, 2.4105032616687425, 2.5896413224967696, 1.7096172787548567, 2.0106988431960406, 2.303569436781081, 3.178983199320621, 1.6280749625114295, 2.094067192561416, 2.915126570900533, 2.890183463276814, 2.987458922879544, 2.6213529891275718, 2.3334396899180563, 2.4070747141358675, 2.7806359635823767, 1.2036119711296438, 0.9232906402955443, 1.0427777679979178, 0.8760767588924415, 1.0152867546975095, 1.1982350634019268, 0.8179504736822626, 1.0254094133776144, 0.7802357474120594, 0.7781835208891713, 0.7790163034262422, 1.0833513834284814, 1.2832829292244234, 0.7196339688902695, 0.7088101447120336, 1.2344332361867045, 0.7070212527947208, 0.7043193708239199, 0.9949019422655998, 0.6981804725556925, 0.6965834812222792, 0.6963184466835863, 0.6885664810447075, 0.68710684596146, 0.6851908785121441, 0.6804269548154904, 0.6793242565056518, 0.6727459890857174, 1.3497833152521779, 0.6712838759329516, 1.1857611376962591, 0.8726281445069384, 1.6037116497678203, 0.9618271418808624, 1.3276517234100058, 1.0658088732559903, 1.0297459080851001, 1.2253853650820368, 1.0121174813624394, 2.380780231383007, 1.4218054238116098, 1.3151990637270312, 1.4970057989862136, 2.7806359635823767, 1.231323504929018, 3.5071977345299707, 2.081086302443789, 3.0910065019102984, 2.915126570900533, 1.5724946110179392, 1.4118840594886704, 1.756759695917464, 2.987458922879544, 2.468420268712991, 7.337138368041865, 3.178983199320621, 5.437436483187529, 2.2038072079373703, 3.3998868676796, 2.890183463276814, 3.0293055225174665, 2.5896413224967696, 2.0100740919718967, 2.5480999496830465, 2.4105032616687425, 2.228918089552586, 2.4070747141358675, 1.2028180033961147, 1.3919287885927, 1.2514861369649593, 0.9355357084462544, 0.7635580941636292, 0.7539306773606291, 1.1932599578968919, 1.2996642995994225, 0.7281810979252288, 0.7257060389097068, 0.7258356582752423, 0.7284153954176757, 0.721867021361196, 0.7160595124992293, 1.088402030049429, 1.4732726760625499, 0.7074620418034105, 0.707364900549223, 0.6995076901710797, 1.2612682151922379, 0.6870030919623886, 0.8945378559755075, 0.8798541393048672, 0.6726597662872438, 0.6697765506018549, 0.6692948525325491, 0.6579407552563605, 0.8250194522344058, 0.643120422391237, 0.641595306742811, 1.3227694617088763, 1.9768741642015955, 1.3983381401501882, 0.8582702610827528, 1.0377026985542457, 1.5750023167194207, 1.0378273007424894, 2.231640377746138, 1.4406051165154958, 2.6213529891275718, 2.2817008040775857, 1.4607387414838269, 5.437436483187529, 7.337138368041865, 1.0034243040578357, 3.0910065019102984, 1.4639621552006383, 1.4373318201812326, 1.4607536274747743, 2.228918089552586, 2.890183463276814, 1.328063842147364, 1.4401646480221588, 3.178983199320621, 2.5480999496830465, 2.468420268712991, 2.987458922879544, 2.1911844166026038], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.8613, -7.2724, -7.2937, -7.3006, -7.1097, -7.2932, -7.3322, -6.9092, -7.2052, -7.2747, -7.2668, -7.4698, -7.4737, -7.148, -7.5105, -7.4739, -6.8919, -7.331, -7.5135, -7.5592, -7.5641, -7.576, -7.576, -7.5985, -7.3566, -7.611, -7.6136, -7.1298, -7.6351, -7.6435, -7.0073, -7.2442, -7.1648, -7.1976, -6.9779, -6.303, -6.8409, -6.4442, -5.7597, -7.0819, -7.0141, -7.0344, -6.7253, -7.1096, -6.1663, -6.5428, -6.775, -6.817, -7.0046, -7.074, -6.8269, -6.8166, -7.0114, -6.9469, -6.893, -6.8029, -7.0585, -6.9788, -6.8819, -6.9258, -6.9425, -6.9678, -7.0124, -7.0223, -7.0227, -6.9437, -7.2387, -7.1296, -7.3111, -7.1838, -7.0204, -7.4085, -7.1881, -7.4768, -7.4806, -7.4795, -7.16, -6.9977, -7.5976, -7.621, -7.0666, -7.6249, -7.6309, -7.2864, -7.6448, -7.6483, -7.6488, -7.6667, -7.6693, -7.6733, -7.685, -7.6869, -7.7024, -7.0064, -7.7064, -7.1387, -7.4468, -6.8671, -7.3567, -7.0653, -7.2751, -7.306, -7.1537, -7.3225, -6.5826, -7.0321, -7.1281, -7.0248, -6.5631, -7.1905, -6.4687, -6.8466, -6.5861, -6.6354, -7.0342, -7.1085, -6.9799, -6.6845, -6.7965, -6.2276, -6.6782, -6.4811, -6.9039, -6.7298, -6.837, -6.8937, -6.9397, -7.0059, -6.9472, -6.99, -7.0142, -7.0191, -6.8529, -6.7083, -6.8322, -7.1492, -7.4389, -7.4579, -7.0091, -6.9268, -7.5111, -7.5159, -7.5161, -7.513, -7.5254, -7.537, -7.1192, -6.8216, -7.5557, -7.5558, -7.5742, -6.9922, -7.6016, -7.3458, -7.364, -7.636, -7.6424, -7.6433, -7.673, -7.4479, -7.7086, -7.7134, -6.9978, -6.6247, -6.9706, -7.4321, -7.2749, -6.9299, -7.2769, -6.6638, -7.0365, -6.609, -6.7262, -7.0437, -6.1241, -5.9193, -7.3139, -6.6426, -7.093, -7.1041, -7.1086, -6.9051, -6.8714, -7.1984, -7.1674, -6.8861, -6.9689, -6.9918, -6.9317, -7.0319], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.7937, 0.7312, 0.726, 0.7213, 0.721, 0.7166, 0.7084, 0.707, 0.6985, 0.6872, 0.6838, 0.6763, 0.6752, 0.6705, 0.6591, 0.657, 0.654, 0.6533, 0.6511, 0.649, 0.6471, 0.6416, 0.6416, 0.6361, 0.6342, 0.6319, 0.6309, 0.6245, 0.6238, 0.621, 0.5977, 0.6065, 0.5948, 0.5908, 0.5486, 0.4131, 0.4995, 0.3873, 0.1872, 0.5208, 0.4983, 0.4953, 0.3798, 0.5195, 0.0803, 0.1422, 0.2854, 0.298, 0.4323, 0.487, 0.2331, 0.1718, 0.3922, 0.2944, 0.2124, -0.0196, 0.394, 0.2219, -0.0119, -0.0472, -0.0971, 0.0084, 0.0801, 0.0391, -0.1055, 0.8108, 0.781, 0.7684, 0.761, 0.7409, 0.7386, 0.7323, 0.7266, 0.7112, 0.71, 0.71, 0.6998, 0.6927, 0.6713, 0.663, 0.6626, 0.6617, 0.6595, 0.6586, 0.6543, 0.6531, 0.653, 0.6463, 0.6458, 0.6446, 0.6399, 0.6396, 0.6338, 0.6335, 0.632, 0.6308, 0.6293, 0.6005, 0.6221, 0.5912, 0.601, 0.6046, 0.5829, 0.6053, 0.4899, 0.5558, 0.5377, 0.5116, 0.354, 0.5413, 0.2163, 0.3604, 0.2253, 0.2346, 0.453, 0.4864, 0.3965, 0.1609, 0.2397, -0.2807, 0.1051, -0.2346, 0.2458, -0.0137, 0.0416, -0.0622, 0.0486, 0.2357, 0.0573, 0.0701, 0.1241, 0.0424, 0.9023, 0.9008, 0.8833, 0.8573, 0.7707, 0.7644, 0.7541, 0.751, 0.746, 0.7445, 0.7442, 0.7437, 0.7403, 0.7368, 0.7359, 0.7308, 0.7303, 0.7303, 0.723, 0.7156, 0.7137, 0.7055, 0.7039, 0.7004, 0.6983, 0.6981, 0.6855, 0.6843, 0.6726, 0.6703, 0.6623, 0.6337, 0.634, 0.6606, 0.6279, 0.5557, 0.6258, 0.4733, 0.5383, 0.3672, 0.3887, 0.5172, 0.1224, 0.0276, 0.6226, 0.1687, 0.4657, 0.473, 0.4524, 0.2332, 0.0072, 0.4578, 0.4077, -0.1028, 0.0356, 0.0444, -0.0862, 0.1235]}, \"token.table\": {\"Topic\": [1, 3, 1, 1, 3, 1, 1, 2, 1, 3, 1, 2, 3, 1, 1, 1, 2, 3, 2, 1, 2, 1, 1, 2, 3, 1, 2, 2, 1, 2, 3, 1, 2, 1, 2, 3, 2, 3, 1, 1, 2, 3, 3, 3, 2, 2, 2, 2, 1, 2, 3, 2, 1, 2, 1, 3, 1, 1, 2, 2, 1, 3, 3, 3, 2, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 3, 1, 1, 1, 1, 2, 3, 1, 1, 2, 3, 1, 3, 2, 1, 1, 3, 1, 2, 1, 2, 3, 1, 2, 2, 1, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 2, 1, 2, 3, 3, 1, 1, 1, 2, 3, 1, 2, 2, 2, 3, 1, 3, 3, 1, 2, 1, 1, 2, 1, 3, 1, 1, 2, 3, 2, 3, 2, 3, 3, 2, 1, 1, 2, 3, 2, 3, 2, 3, 1, 2, 3, 1, 1, 1, 2, 1, 3, 2, 2, 1, 2, 3, 2, 3, 3, 2, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1], \"Freq\": [1.3201392596794612, 0.752975849702441, 0.8965604314098925, 1.0724538596450848, 1.1651341603499668, 1.2325603721127893, 0.7082734543813471, 0.7082734543813471, 0.4382695567328189, 0.4382695567328189, 0.2851279214041858, 0.2851279214041858, 0.2851279214041858, 0.614222331911194, 0.8306202912423687, 0.38615386281983743, 0.38615386281983743, 0.38615386281983743, 1.283670181999831, 0.6635175767630603, 0.6635175767630603, 1.3201392567808519, 1.2290592139501988, 0.9880275940436009, 0.769429459829139, 0.5882548678347602, 0.2941274339173801, 0.938254526766185, 0.3678203885569918, 0.1839101942784959, 0.3678203885569918, 1.2519550139945466, 0.740859654064676, 0.40887875483812636, 0.2725858365587509, 0.2725858365587509, 0.7033311191901183, 0.6941527477139454, 1.25828849808927, 0.44864816014873454, 0.44864816014873454, 0.44864816014873454, 0.963551449537484, 0.6943650515052872, 0.8100883633764644, 0.7792513850428674, 1.0830825704892895, 1.0051241811055176, 0.3347326359339939, 0.3347326359339939, 0.3347326359339939, 1.2816639116021922, 0.43400543485672155, 0.43400543485672155, 1.0831362282665675, 0.6830777670362308, 0.6047489216524778, 1.0522774408504965, 1.285043917220678, 0.9711133515058922, 0.8857340997653876, 1.1365520207588664, 0.7559896330749178, 1.326381894288761, 0.9230615433704443, 0.7151346096392646, 0.6614200402266601, 1.0223206442937989, 1.3117154988462092, 0.34599879651453896, 0.34599879651453896, 0.34599879651453896, 0.7184275576418266, 0.838040356070013, 0.652150333451134, 1.068906286496331, 0.5849262360803448, 0.9147096698781841, 0.5491181794925334, 0.35962995987136337, 0.35962995987136337, 0.35962995987136337, 1.210556209971328, 0.7137959700942547, 0.6680000843531865, 0.6349197009963162, 0.6845851154630117, 0.6845851154630117, 0.6359322270444283, 0.6846894997887611, 0.505849091514569, 0.505849091514569, 1.1059826145929375, 1.1414524924325413, 0.3814823887311781, 0.3814823887311781, 0.3814823887311781, 0.42003036937982935, 0.42003036937982935, 0.753209582277761, 1.3427620150741153, 0.7154403008593787, 0.4563741839449935, 0.4563741839449935, 0.4563741839449935, 0.477539595459123, 0.477539595459123, 0.477539595459123, 0.41498498428434266, 0.41498498428434266, 0.41498498428434266, 0.9849434116747993, 0.6602173287354406, 0.3301086643677203, 0.7603411738799332, 0.3235192159518208, 0.3235192159518208, 0.3235192159518208, 0.7990500018043742, 0.7234769480455181, 0.7328973834268836, 0.3145659908532104, 0.3145659908532104, 0.3145659908532104, 0.8594181746521328, 0.6235534923904659, 1.2225679086634476, 1.14596349693148, 0.9965873817845673, 1.085515077095219, 1.117895674643623, 0.831380971332766, 1.0107565313773772, 0.8345607890666171, 1.065839111521516, 0.497494099343867, 0.497494099343867, 0.4973395212236173, 0.4973395212236173, 0.6743839204362916, 0.4341089024854234, 0.4341089024854234, 0.4341089024854234, 1.0396878570555725, 0.9187781466693752, 0.9589771000967454, 1.309658043891683, 1.2120926328363448, 0.8160698083194851, 1.0454515502723845, 1.3076923604157469, 0.6957335710232244, 0.6957335710232244, 0.5692298168747275, 0.6787609763269264, 0.9752202261398032, 0.9636671480118785, 0.4051173994456745, 0.4051173994456745, 0.4051173994456745, 0.9645216335305826, 0.7521338460714561, 0.41485112918192873, 0.41485112918192873, 0.44810087233228746, 0.44810087233228746, 0.8433401704687651, 0.8308325473544893, 0.3924492836807238, 0.3924492836807238, 0.3924492836807238, 0.480518274915228, 0.480518274915228, 0.6845781391135165, 0.8121342571606694, 0.4154420276725797, 0.4154420276725797, 0.4154420276725797, 0.7928527714841238, 0.42855189457890686, 0.42855189457890686, 0.42855189457890686, 0.343038278331456, 0.343038278331456, 0.343038278331456, 0.4537602002563279, 0.4537602002563279, 0.8350472394892378], \"Term\": [\"200\", \"across\", \"adaptation\", \"addressing\", \"affected\", \"agriculture\", \"air\", \"air\", \"already\", \"already\", \"also\", \"also\", \"also\", \"around\", \"ask\", \"australia\", \"australia\", \"australia\", \"bad\", \"become\", \"become\", \"beep\", \"benefit\", \"biodiversity\", \"can\\u00e2\", \"carbon\", \"carbon\", \"causes\", \"change\", \"change\", \"change\", \"circulation\", \"cities\", \"climate\", \"climate\", \"climate\", \"come\", \"conditions\", \"consume\", \"countries\", \"countries\", \"countries\", \"create\", \"current\", \"data\", \"dioxide\", \"education\", \"effect\", \"emissions\", \"emissions\", \"emissions\", \"end\", \"energy\", \"energy\", \"enough\", \"even\", \"evidence\", \"fall\", \"farmers\", \"federal\", \"financial\", \"fires\", \"five\", \"focus\", \"focused\", \"forests\", \"fossil\", \"fuels\", \"gases\", \"global\", \"global\", \"global\", \"growth\", \"happening\", \"help\", \"here\\u00e2\", \"high\", \"hope\", \"human\", \"ice\", \"ice\", \"ice\", \"islands\", \"large\", \"last\", \"least\", \"less\", \"less\", \"level\", \"levels\", \"likely\", \"likely\", \"limited\", \"livestock\", \"many\", \"many\", \"many\", \"may\", \"may\", \"mean\", \"meltwater\", \"mitigation\", \"much\", \"much\", \"much\", \"natural\", \"natural\", \"natural\", \"need\", \"need\", \"need\", \"needs\", \"new\", \"new\", \"often\", \"one\", \"one\", \"one\", \"others\", \"paris\", \"part\", \"people\", \"people\", \"people\", \"pollution\", \"power\", \"present\", \"president\", \"problems\", \"produce\", \"protect\", \"provide\", \"published\", \"rainfall\", \"really\", \"research\", \"research\", \"science\", \"science\", \"scientific\", \"sea\", \"sea\", \"sea\", \"second\", \"see\", \"seen\", \"short\", \"small\", \"state\", \"studies\", \"sustainable\", \"take\", \"take\", \"temperatures\", \"term\", \"that\\u00e2\", \"threat\", \"time\", \"time\", \"time\", \"university\", \"urban\", \"us\", \"us\", \"use\", \"use\", \"view\", \"warmer\", \"warming\", \"warming\", \"warming\", \"water\", \"water\", \"well\", \"whether\", \"world\", \"world\", \"world\", \"world\\u00e2\", \"would\", \"would\", \"would\", \"year\", \"year\", \"year\", \"years\", \"years\", \"yet\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 3, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el3301401153889646883465307712\", ldavis_el3301401153889646883465307712_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el3301401153889646883465307712\", ldavis_el3301401153889646883465307712_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el3301401153889646883465307712\", ldavis_el3301401153889646883465307712_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0     -0.025673 -0.007284       1        1  35.605495\n",
       "2      0.019309 -0.018027       2        1  33.489133\n",
       "1      0.006364  0.025311       3        1  30.905372, topic_info=           Term      Freq     Total Category  logprob  loglift\n",
       "1988     growth  1.000000  1.000000  Default  30.0000  30.0000\n",
       "3308    provide  1.000000  1.000000  Default  29.0000  29.0000\n",
       "2945     others  1.000000  1.000000  Default  28.0000  28.0000\n",
       "296     already  2.000000  2.000000  Default  27.0000  27.0000\n",
       "4435      urban  1.000000  1.000000  Default  26.0000  26.0000\n",
       "...         ...       ...       ...      ...      ...      ...\n",
       "3055     people  0.886482  3.178983   Topic3  -6.8861  -0.1028\n",
       "4537    warming  0.816013  2.548100   Topic3  -6.9689   0.0356\n",
       "4248       time  0.797540  2.468420   Topic3  -6.9918   0.0444\n",
       "1449  emissions  0.846996  2.987459   Topic3  -6.9317  -0.0862\n",
       "2749       much  0.766242  2.191184   Topic3  -7.0319   0.1235\n",
       "\n",
       "[220 rows x 6 columns], token_table=      Topic      Freq        Term\n",
       "term                             \n",
       "60        1  1.320139         200\n",
       "190       3  0.752976      across\n",
       "207       1  0.896560  adaptation\n",
       "218       1  1.072454  addressing\n",
       "239       3  1.165134    affected\n",
       "...     ...       ...         ...\n",
       "4651      2  0.343038        year\n",
       "4651      3  0.343038        year\n",
       "4652      1  0.453760       years\n",
       "4652      2  0.453760       years\n",
       "4654      1  0.835047         yet\n",
       "\n",
       "[188 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 3, 2])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.sklearn.prepare(lda, X, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-dodge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
