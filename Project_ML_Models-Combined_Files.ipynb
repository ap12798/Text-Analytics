{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "peripheral-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "public-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"AP_JJ_SAsentiments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "false-healthcare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It also increases carbon dioxide emissions whi...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We can already see this happening.\\t</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The ecological disaster is a consequence of no...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We may be dealing with an issue with a level o...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Preventable chronic diseases are Australiaâ€™s...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence sentiment\n",
       "0  It also increases carbon dioxide emissions whi...   neutral\n",
       "1               We can already see this happening.\\t  negative\n",
       "2  The ecological disaster is a consequence of no...  positive\n",
       "3  We may be dealing with an issue with a level o...  negative\n",
       "4  Preventable chronic diseases are Australiaâ€™s...  negative"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cultural-anthropology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     1250\n",
       "negative     681\n",
       "positive     469\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "general-reviewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True, norm=\"l2\", stop_words=\"english\", max_df=0.7)\n",
    "X = vectorizer.fit_transform(df.sentence)\n",
    "y = df.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bronze-tobago",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2400, 8186), (2400,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "joint-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-overview",
   "metadata": {},
   "source": [
    "## K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "impossible-dress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1: [0.51785714 0.51488095 0.52380952 0.51785714 0.52380952]\n",
      "0.520, 0.004\n",
      "\n",
      "k = 3: [0.29464286 0.52380952 0.52380952 0.52678571 0.52678571]\n",
      "0.479, 0.092\n",
      "\n",
      "k = 10: [0.48511905 0.49404762 0.52380952 0.52380952 0.38095238]\n",
      "0.482, 0.053\n",
      "\n",
      "k = 30: [0.51785714 0.52083333 0.52380952 0.5297619  0.47619048]\n",
      "0.514, 0.019\n",
      "\n",
      "Highest score : 0.520 when k = 1\n"
     ]
    }
   ],
   "source": [
    "score_max = 0                      # Score_max is a temoporay variable to store the max score \n",
    "for param in [1, 3, 10, 30]:\n",
    "    model = KNeighborsClassifier(n_neighbors=param)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    print(\"k = {}: {}\\n{:.3f}, {:.3f}\\n\".format(param, scores, scores.mean(), scores.std()))\n",
    "    \n",
    "    if scores.mean() > score_max:\n",
    "        score_max = scores.mean()\n",
    "        param_best = param         # Param_best is a temoporay variable to store the best parameter \n",
    "        \n",
    "print(\"Highest score : {:.3f} when k = {}\".format(score_max, param_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "separate-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(X_train, X_test, y_train, y_test, classifier):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    \n",
    "    print(\"Train score: {:.2f}\".format(classifier.score(X_train, y_train)))\n",
    "    print(\"Test score: {:.2f}\\n\".format(classifier.score(X_test, y_test)))\n",
    "    print(\"Classification report:\\n{}\".format(classification_report(y_test, pred, zero_division=0)))\n",
    "    print(confusion_matrix(y_test,pred))\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "technical-fever",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Train score: 1.00\n",
      "Test score: 0.51\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.29      0.01      0.02       218\n",
      "     neutral       0.51      0.98      0.67       368\n",
      "    positive       0.00      0.00      0.00       134\n",
      "\n",
      "    accuracy                           0.51       720\n",
      "   macro avg       0.27      0.33      0.23       720\n",
      "weighted avg       0.35      0.51      0.35       720\n",
      "\n",
      "[[  2 214   2]\n",
      " [  4 362   2]\n",
      " [  1 133   0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"k = {}\".format(param_best))\n",
    "knn = KNeighborsClassifier(n_neighbors=param_best)\n",
    "knn = train_test(X_train, X_test, y_train, y_test, knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "controversial-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {}\n",
    "summary[\"k-NNs\"] = round(knn.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-surgeon",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "after-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "minimal-hierarchy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54464286 0.53571429 0.54464286 0.55654762 0.53869048]\n",
      "0.544, 0.007\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(lr, X_train, y_train, cv=5)\n",
    "print(\"{}\\n{:.3f}, {:.3f}\".format(scores, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "selected-cooperative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.83\n",
      "Test score: 0.53\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.54      0.13      0.21       218\n",
      "     neutral       0.53      0.95      0.68       368\n",
      "    positive       0.22      0.01      0.03       134\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.43      0.36      0.30       720\n",
      "weighted avg       0.47      0.53      0.41       720\n",
      "\n",
      "[[ 28 184   6]\n",
      " [ 19 348   1]\n",
      " [  5 127   2]]\n"
     ]
    }
   ],
   "source": [
    "lr = train_test(X_train, X_test, y_train, y_test, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "color-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"Logistic Regression\"] = round(lr.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-dealer",
   "metadata": {},
   "source": [
    "## Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "humanitarian-superior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "latin-manitoba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52380952 0.53869048 0.5297619  0.54761905 0.54166667]\n",
      "0.536, 0.009\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(mnb, X_train, y_train, cv=5)\n",
    "print(\"{}\\n{:.3f}, {:.3f}\".format(scores, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "underlying-virginia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.70\n",
      "Test score: 0.53\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.06      0.10       218\n",
      "     neutral       0.52      1.00      0.68       368\n",
      "    positive       0.00      0.00      0.00       134\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.48      0.35      0.26       720\n",
      "weighted avg       0.54      0.53      0.38       720\n",
      "\n",
      "[[ 12 206   0]\n",
      " [  1 367   0]\n",
      " [  0 134   0]]\n"
     ]
    }
   ],
   "source": [
    "mnb = train_test(X_train, X_test, y_train, y_test, mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "rough-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"Multinomial Naive Bayes\"] = round(mnb.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-detail",
   "metadata": {},
   "source": [
    "## Modeling with Linear Support Vector Machines (SVMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "expired-identifier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC(C=1)\n",
    "svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "boolean-screening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.99\n",
      "Test score: 0.50\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.27      0.34       218\n",
      "     neutral       0.54      0.78      0.63       368\n",
      "    positive       0.24      0.11      0.15       134\n",
      "\n",
      "    accuracy                           0.50       720\n",
      "   macro avg       0.42      0.39      0.38       720\n",
      "weighted avg       0.46      0.50      0.46       720\n",
      "\n",
      "[[ 58 143  17]\n",
      " [ 50 287  31]\n",
      " [ 13 106  15]]\n"
     ]
    }
   ],
   "source": [
    "svm = train_test(X_train, X_test, y_train, y_test, svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "varying-creek",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.01: [0.52380952 0.52380952 0.52380952 0.52678571 0.52678571]\n",
      "0.525, 0.001\n",
      "\n",
      "C = 0.03: [0.52380952 0.52380952 0.52380952 0.52678571 0.52678571]\n",
      "0.525, 0.001\n",
      "\n",
      "C = 0.1: [0.5297619  0.53869048 0.53571429 0.53869048 0.53571429]\n",
      "0.536, 0.003\n",
      "\n",
      "C = 0.3: [0.54761905 0.55654762 0.54464286 0.57440476 0.52678571]\n",
      "0.550, 0.016\n",
      "\n",
      "C = 1: [0.5327381  0.5297619  0.55357143 0.56845238 0.50892857]\n",
      "0.539, 0.021\n",
      "\n",
      "C = 3: [0.53571429 0.52678571 0.51190476 0.55952381 0.50892857]\n",
      "0.529, 0.018\n",
      "\n",
      "C = 10: [0.51785714 0.53571429 0.51785714 0.54166667 0.48214286]\n",
      "0.519, 0.021\n",
      "\n",
      "Highest score : 0.550 when C = 0.3\n"
     ]
    }
   ],
   "source": [
    "score_max = 0\n",
    "for param in [0.01, 0.03, 0.1, 0.3, 1, 3, 10]:\n",
    "    model = LinearSVC(C=param)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    print(\"C = {}: {}\\n{:.3f}, {:.3f}\\n\".format(param, scores, scores.mean(), scores.std()))\n",
    "    \n",
    "    if scores.mean() > score_max:\n",
    "        score_max = scores.mean()\n",
    "        param_best = param\n",
    "        \n",
    "print(\"Highest score : {:.3f} when C = {}\".format(score_max, param_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "abstract-satisfaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.3\n",
      "Train score: 0.95\n",
      "Test score: 0.53\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.19      0.28       218\n",
      "     neutral       0.54      0.90      0.67       368\n",
      "    positive       0.20      0.03      0.05       134\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.42      0.38      0.34       720\n",
      "weighted avg       0.47      0.53      0.44       720\n",
      "\n",
      "[[ 42 167   9]\n",
      " [ 28 333   7]\n",
      " [  9 121   4]]\n"
     ]
    }
   ],
   "source": [
    "print(\"C = {}\".format(param_best))\n",
    "svm = LinearSVC(C=param_best)\n",
    "svm = train_test(X_train, X_test, y_train, y_test, svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "adapted-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"Linear SVMs\"] = round(svm.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-playing",
   "metadata": {},
   "source": [
    "## Modeling with Kernelized Support Vector Machines (KSVMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "sized-fellowship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksvm = SVC(C=1, kernel=\"rbf\", gamma=\"scale\")\n",
    "ksvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "white-petite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.99\n",
      "Test score: 0.51\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.02      0.04       218\n",
      "     neutral       0.51      0.99      0.68       368\n",
      "    positive       0.00      0.00      0.00       134\n",
      "\n",
      "    accuracy                           0.51       720\n",
      "   macro avg       0.36      0.34      0.24       720\n",
      "weighted avg       0.43      0.51      0.36       720\n",
      "\n",
      "[[  5 212   1]\n",
      " [  3 365   0]\n",
      " [  1 133   0]]\n"
     ]
    }
   ],
   "source": [
    "ksvm = train_test(X_train, X_test, y_train, y_test, ksvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "accompanied-cuisine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.01: [0.52380952 0.52380952 0.52380952 0.52678571 0.52678571]\n",
      "0.525, 0.001\n",
      "\n",
      "C = 0.03: [0.52380952 0.52380952 0.52380952 0.52678571 0.52678571]\n",
      "0.525, 0.001\n",
      "\n",
      "C = 0.1: [0.52380952 0.52380952 0.52380952 0.52678571 0.52678571]\n",
      "0.525, 0.001\n",
      "\n",
      "C = 0.3: [0.52380952 0.52380952 0.52380952 0.52678571 0.52678571]\n",
      "0.525, 0.001\n",
      "\n",
      "C = 1: [0.52380952 0.52678571 0.52678571 0.5327381  0.5297619 ]\n",
      "0.528, 0.003\n",
      "\n",
      "C = 3: [0.53869048 0.54464286 0.54166667 0.55059524 0.53571429]\n",
      "0.542, 0.005\n",
      "\n",
      "C = 10: [0.53869048 0.54464286 0.54166667 0.55059524 0.53571429]\n",
      "0.542, 0.005\n",
      "\n",
      "Highest score : 0.542 when C = 3\n"
     ]
    }
   ],
   "source": [
    "score_max = 0\n",
    "for param in [0.01, 0.03, 0.1, 0.3, 1, 3, 10]:\n",
    "    model = SVC(C=param, kernel=\"rbf\", gamma=\"scale\")\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    print(\"C = {}: {}\\n{:.3f}, {:.3f}\\n\".format(param, scores, scores.mean(), scores.std()))\n",
    "    \n",
    "    if scores.mean() > score_max:\n",
    "        score_max = scores.mean()\n",
    "        param_best = param\n",
    "        \n",
    "print(\"Highest score : {:.3f} when C = {}\".format(score_max, param_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ideal-breeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 3\n",
      "Train score: 1.00\n",
      "Test score: 0.52\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.13      0.21       218\n",
      "     neutral       0.53      0.94      0.68       368\n",
      "    positive       0.18      0.01      0.03       134\n",
      "\n",
      "    accuracy                           0.52       720\n",
      "   macro avg       0.41      0.36      0.30       720\n",
      "weighted avg       0.46      0.52      0.41       720\n",
      "\n",
      "[[ 28 184   6]\n",
      " [ 19 346   3]\n",
      " [  6 126   2]]\n"
     ]
    }
   ],
   "source": [
    "print(\"C = {}\".format(param_best))\n",
    "ksvm = SVC(C=param_best)\n",
    "ksvm = train_test(X_train, X_test, y_train, y_test, ksvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "polished-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"Kernelized SVMs\"] = round(ksvm.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-oxide",
   "metadata": {},
   "source": [
    "## Modeling with Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "strategic-married",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(10,), random_state=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(10, ), activation=\"relu\", random_state=0)\n",
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ready-tender",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 0.44\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.39      0.40        88\n",
      "     neutral       0.47      0.62      0.53       105\n",
      "     postive       0.35      0.13      0.19        47\n",
      "\n",
      "    accuracy                           0.44       240\n",
      "   macro avg       0.41      0.38      0.37       240\n",
      "weighted avg       0.42      0.44      0.41       240\n",
      "\n",
      "[[34 49  5]\n",
      " [34 65  6]\n",
      " [16 25  6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp = train_test(X_train, X_test, y_train, y_test, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "tough-yorkshire",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_layer_size = 10: [0.5        0.47321429 0.30357143 0.42857143 0.45045045]\n",
      "0.431, 0.068\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_layer_size = 30: [0.44642857 0.44642857 0.32142857 0.41964286 0.46846847]\n",
      "0.420, 0.052\n",
      "\n",
      "hidden_layer_size = 100: [0.46428571 0.45535714 0.33928571 0.41964286 0.45045045]\n",
      "0.426, 0.046\n",
      "\n",
      "Highest score : 0.431 when hidden_layer_sizes = 10\n"
     ]
    }
   ],
   "source": [
    "score_max = 0\n",
    "for param in [10, 30, 100]:\n",
    "    model = MLPClassifier(hidden_layer_sizes=(param, ), activation=\"relu\", random_state=0)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    print(\"hidden_layer_size = {}: {}\\n{:.3f}, {:.3f}\\n\".format(param, scores, scores.mean(), scores.std()))\n",
    "    \n",
    "    if scores.mean() > score_max:\n",
    "        score_max = scores.mean()\n",
    "        param_best = param\n",
    "        \n",
    "print(\"Highest score : {:.3f} when hidden_layer_sizes = {}\".format(score_max, param_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "north-sheriff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_layer_size = 10\n",
      "Train score: 1.00\n",
      "Test score: 0.44\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.39      0.40        88\n",
      "     neutral       0.47      0.62      0.53       105\n",
      "     postive       0.35      0.13      0.19        47\n",
      "\n",
      "    accuracy                           0.44       240\n",
      "   macro avg       0.41      0.38      0.37       240\n",
      "weighted avg       0.42      0.44      0.41       240\n",
      "\n",
      "[[34 49  5]\n",
      " [34 65  6]\n",
      " [16 25  6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aportr/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"hidden_layer_size = {}\".format(param_best))\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(param_best, ), random_state=0)\n",
    "mlp = train_test(X_train, X_test, y_train, y_test, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "awful-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"Neural Networks\"] = round(mlp.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-kidney",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "widespread-catch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "meaningful-comment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49702381 0.49702381 0.5327381  0.52380952 0.49404762]\n",
      "0.509, 0.016\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(dt, X_train, y_train, cv=5)\n",
    "print(\"{}\\n{:.3f}, {:.3f}\".format(scores, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "german-blowing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 0.51\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.32      0.37       218\n",
      "     neutral       0.58      0.74      0.65       368\n",
      "    positive       0.24      0.17      0.20       134\n",
      "\n",
      "    accuracy                           0.51       720\n",
      "   macro avg       0.42      0.41      0.41       720\n",
      "weighted avg       0.47      0.51      0.48       720\n",
      "\n",
      "[[ 69 116  33]\n",
      " [ 58 272  38]\n",
      " [ 33  78  23]]\n"
     ]
    }
   ],
   "source": [
    "dt = train_test(X_train, X_test, y_train, y_test, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "supported-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"Decision Tree\"] = round(dt.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-diagnosis",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "stock-software",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 1: [0.52380952 0.52380952 0.52380952 0.52678571 0.52678571]\n",
      "0.525, 0.001\n",
      "\n",
      "C = 3: [0.52380952 0.52380952 0.52380952 0.52678571 0.52678571]\n",
      "0.525, 0.001\n",
      "\n",
      "C = 10: [0.52678571 0.52380952 0.52380952 0.52678571 0.5297619 ]\n",
      "0.526, 0.002\n",
      "\n",
      "C = 12: [0.52380952 0.52380952 0.52380952 0.52678571 0.52678571]\n",
      "0.525, 0.001\n",
      "\n",
      "C = 14: [0.52678571 0.52380952 0.52380952 0.52678571 0.5327381 ]\n",
      "0.527, 0.003\n",
      "\n",
      "C = 16: [0.52380952 0.52380952 0.52380952 0.52678571 0.5297619 ]\n",
      "0.526, 0.002\n",
      "\n",
      "C = 18: [0.52380952 0.52083333 0.52380952 0.5297619  0.5297619 ]\n",
      "0.526, 0.004\n",
      "\n",
      "C = 20: [0.52678571 0.52678571 0.52678571 0.5297619  0.5297619 ]\n",
      "0.528, 0.001\n",
      "\n",
      "Highest score : 0.528 when C = 20\n"
     ]
    }
   ],
   "source": [
    "score_max = 0\n",
    "for param in [1, 3, 10, 12, 14, 16, 18, 20]:\n",
    "    model = RandomForestClassifier(max_depth=param)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    print(\"C = {}: {}\\n{:.3f}, {:.3f}\\n\".format(param, scores, scores.mean(), scores.std()))\n",
    "    \n",
    "    if scores.mean() > score_max:\n",
    "        score_max = scores.mean()\n",
    "        param_best = param\n",
    "        \n",
    "print(\"Highest score : {:.3f} when C = {}\".format(score_max, param_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "established-track",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 20\n",
      "Train score: 0.57\n",
      "Test score: 0.51\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.01      0.02       218\n",
      "     neutral       0.51      0.99      0.68       368\n",
      "    positive       0.00      0.00      0.00       134\n",
      "\n",
      "    accuracy                           0.51       720\n",
      "   macro avg       0.30      0.33      0.23       720\n",
      "weighted avg       0.38      0.51      0.35       720\n",
      "\n",
      "[[  2 216   0]\n",
      " [  2 366   0]\n",
      " [  1 133   0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"C = {}\".format(param_best))\n",
    "rf = RandomForestClassifier(max_depth=param_best)\n",
    "rf = train_test(X_train, X_test, y_train, y_test, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "convinced-beast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=16, n_estimators=10)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rf = RandomForestClassifier(max_depth = 16, n_estimators=10)\n",
    "# rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "dynamic-freedom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45535714 0.41964286 0.41071429 0.42857143 0.40540541]\n",
      "0.424, 0.018\n"
     ]
    }
   ],
   "source": [
    "# scores = cross_val_score(rf, X_train, y_train, cv=5)\n",
    "# print(\"{}\\n{:.3f}, {:.3f}\".format(scores, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "unique-calgary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.61\n",
      "Test score: 0.42\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.41      0.14      0.21        88\n",
      "     neutral       0.43      0.85      0.57       105\n",
      "     postive       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.42       240\n",
      "   macro avg       0.28      0.33      0.26       240\n",
      "weighted avg       0.34      0.42      0.32       240\n",
      "\n",
      "[[12 74  2]\n",
      " [14 89  2]\n",
      " [ 3 44  0]]\n"
     ]
    }
   ],
   "source": [
    "# rf = train_test(X_train, X_test, y_train, y_test, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "altered-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"Random Forest\"] = round(rf.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "stainless-mediterranean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.506,\n",
       " 'Logistic Regression': 0.525,\n",
       " 'Multinomial Naive Bayes': 0.526,\n",
       " 'Linear SVMs': 0.526,\n",
       " 'Kernelized SVMs': 0.522,\n",
       " 'Decision Tree': 0.506,\n",
       " 'Random Forest': 0.511}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-heading",
   "metadata": {},
   "source": [
    "## New sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "spread-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"This is amazing, climate change initiatives have created so many jobs!\"\n",
    "text2 = \"I hate the bad idea of hotter temperatures and the horrible fact that ice caps are melting\"\n",
    "text3 = \"Ice caps are melting faster each year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fifth-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_texts = [text1, text2, text3]\n",
    "X_new = vectorizer.transform(new_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "coordinate-casino",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'neutral', 'neutral'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "coordinate-malaysia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'neutral', 'neutral'], dtype='<U8')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "invisible-equity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'neutral', 'neutral'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "personal-hammer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'neutral', 'neutral'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksvm.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dimensional-tribute",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-670443391e1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mlp' is not defined"
     ]
    }
   ],
   "source": [
    "mlp.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "compliant-thesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'positive', 'neutral'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "vietnamese-boards",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'neutral', 'neutral'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-delight",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-jimmy",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ordered-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates([\"sentence\"], keep=\"first\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "personalized-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string \n",
    "\n",
    "global_stopwords = stopwords.words(\"english\")\n",
    "local_stopwords = [c for c in string.punctuation] +\\\n",
    "                  ['’', '``', '…', '...', \"''\", '‘', '“', '”', \"'m\", \"'re\", \"'s\", \"'ve\", 'amp', 'https', \"n't\", 'rt', \n",
    "                   'covid19', 'coronavirus', 'covid19…', 'covid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "historical-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf=True, norm=\"l2\", stop_words=global_stopwords+local_stopwords, max_df=0.7)\n",
    "X = vectorizer.fit_transform(df.sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "spatial-thailand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2375, 8319)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "thermal-three",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=10, random_state=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10\n",
    "kmeans = KMeans(n_clusters = k, random_state=0)\n",
    "kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "binding-andrew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.9 s, sys: 22.4 ms, total: 8.92 s\n",
      "Wall time: 1.22 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=10, random_state=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "under-alberta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.00333934, 0.        , 0.00242854, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.00109347, 0.0004104 , 0.        , ..., 0.00083695, 0.00035438,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.00333804, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "divine-probe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 8319)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "iraqi-karaoke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 4, ..., 3, 6, 0], dtype=int32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "underlying-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cluster\"] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "included-still",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It also increases carbon dioxide emissions whi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We can already see this happening.\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The ecological disaster is a consequence of no...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We may be dealing with an issue with a level o...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Preventable chronic diseases are Australiaâ€™s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>Earthâ€™s cornucopia of life has evolved over ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>This is because they seem to be more effective...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>Are climate scientists saying</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>[Understand new developments in science</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>Everybody is important.\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2375 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  cluster\n",
       "0     It also increases carbon dioxide emissions whi...        3\n",
       "1                  We can already see this happening.\\t        2\n",
       "2     The ecological disaster is a consequence of no...        4\n",
       "3     We may be dealing with an issue with a level o...        2\n",
       "4     Preventable chronic diseases are Australiaâ€™s...        0\n",
       "...                                                 ...      ...\n",
       "2395  Earthâ€™s cornucopia of life has evolved over ...        0\n",
       "2396  This is because they seem to be more effective...        2\n",
       "2397                      Are climate scientists saying        3\n",
       "2398            [Understand new developments in science        6\n",
       "2399                          Everybody is important.\\t        0\n",
       "\n",
       "[2375 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"sentence\", \"cluster\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "medical-corps",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    989\n",
       "4    251\n",
       "3    236\n",
       "5    229\n",
       "0    225\n",
       "1    140\n",
       "6    121\n",
       "8     72\n",
       "9     59\n",
       "7     53\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cluster.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "several-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df.cluster.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "local-blake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>For example, a failure in the water supply wil...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>But the evidence on this is not clear and a re...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>I think if we were to pursue an â€œeither/orâ€...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>More specifically, the first anniversaries of ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>At the same time, adaptation measures may bene...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>Research has also found that prolonged exposur...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>Climate change is the defining issue of our ti...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>In other words, the waiting time for the recen...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>In time steps of 500 years</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>Iron ore and coal led the way.About the same t...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  cluster\n",
       "1271  For example, a failure in the water supply wil...        7\n",
       "55    But the evidence on this is not clear and a re...        7\n",
       "2170  I think if we were to pursue an â€œeither/orâ€...        7\n",
       "1296  More specifically, the first anniversaries of ...        7\n",
       "1278  At the same time, adaptation measures may bene...        7\n",
       "1918  Research has also found that prolonged exposur...        7\n",
       "1320  Climate change is the defining issue of our ti...        7\n",
       "1461  In other words, the waiting time for the recen...        7\n",
       "1908                         In time steps of 500 years        7\n",
       "855   Iron ore and coal led the way.About the same t...        7"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.cluster == counts.idxmin()].sample(10, random_state=1)[[\"sentence\", \"cluster\"]] #largest cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "traditional-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "df[\"words\"] = df.sentence.apply(lambda x: nltk.word_tokenize(x))\n",
    "df[\"tagged_words\"] = df.words.apply(lambda x: nltk.pos_tag(x))\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def get_counter(dataframe, stopwords=[]):\n",
    "    counter = Counter()\n",
    "    \n",
    "    for l in dataframe.tagged_words:\n",
    "        word_set = set()\n",
    "\n",
    "        for t in l:\n",
    "            word = t[0].lower()\n",
    "            tag = t[1]\n",
    "\n",
    "            if word not in stopwords:\n",
    "                word_set.add(word)\n",
    "            \n",
    "        counter.update(word_set)\n",
    "        \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "particular-works",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('example', 12),\n",
       " ('good', 9),\n",
       " ('may', 8),\n",
       " ('also', 7),\n",
       " ('much', 6),\n",
       " ('use', 6),\n",
       " ('areas', 5),\n",
       " ('problem', 5),\n",
       " ('view', 5),\n",
       " ('world', 5),\n",
       " ('provide', 5),\n",
       " ('federal', 4),\n",
       " ('australia', 4),\n",
       " ('know', 4),\n",
       " ('whether', 4),\n",
       " ('sea', 4),\n",
       " ('summer', 4),\n",
       " ('many', 4),\n",
       " ('could', 4),\n",
       " ('means', 4),\n",
       " ('canâ€™t', 4),\n",
       " ('people', 4),\n",
       " ('year', 4),\n",
       " ('like', 4),\n",
       " ('would', 4),\n",
       " ('made', 4),\n",
       " ('health', 3),\n",
       " ('conditions', 3),\n",
       " ('quickly', 3),\n",
       " ('since', 3)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_max = get_counter(df[df.cluster == counts.idxmax()], global_stopwords+local_stopwords)\n",
    "counter_max.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "passing-marijuana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('time', 49),\n",
       " ('climate', 7),\n",
       " ('change', 6),\n",
       " ('people', 5),\n",
       " ('first', 5),\n",
       " ('may', 4),\n",
       " ('years', 4),\n",
       " ('others', 3),\n",
       " ('look', 3),\n",
       " ('communities', 3),\n",
       " ('found', 3),\n",
       " ('high', 3),\n",
       " ('around', 3),\n",
       " ('â€', 3),\n",
       " ('carbon', 3),\n",
       " ('likely', 3),\n",
       " ('increased', 3),\n",
       " ('events', 2),\n",
       " ('challenges', 2),\n",
       " ('immediate', 2),\n",
       " ('still', 2),\n",
       " ('buildings', 2),\n",
       " ('whether', 2),\n",
       " ('environment', 2),\n",
       " ('clear', 2),\n",
       " ('effect', 2),\n",
       " ('fixed', 2),\n",
       " ('followed', 2),\n",
       " ('rainfall', 2),\n",
       " ('period', 2)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_min = get_counter(df[df.cluster == counts.idxmin()], global_stopwords+local_stopwords)\n",
    "counter_min.most_common(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-graduation",
   "metadata": {},
   "source": [
    "### LDA Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "instant-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_stopwords = stopwords.words(\"english\")\n",
    "local_stopwords = [c for c in string.punctuation] +\\\n",
    "                  ['’', '``', '…', '...', \"''\", '‘', '“', '”', \"'m\", \"'re\", \"'s\", \"'ve\", 'amp', 'https', \"n't\", 'rt', \n",
    "                   'covid19', 'coronavirus', 'covid19…', 'covid', 'co', 'cases']\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf=True, norm=\"l2\", stop_words=global_stopwords+local_stopwords, max_df=0.7)\n",
    "X = vectorizer.fit_transform(df.sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "described-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "solved-least",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=3, random_state=0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "lda = LDA(n_components=num_topics, random_state=0)     # LDA uses randomness to get a probability distribution\n",
    "lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "arbitrary-advocate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.8 s, sys: 0 ns, total: 3.8 s\n",
      "Wall time: 3.81 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=3, random_state=0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time lda.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "running-processor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.32372288, 0.33490431, 0.33453344, ..., 1.15679968, 0.33415654,\n",
       "        0.33405415],\n",
       "       [0.92142793, 0.736381  , 0.33416588, ..., 0.33545675, 0.68191458,\n",
       "        0.5974671 ],\n",
       "       [1.16130358, 0.3346012 , 0.67129594, ..., 0.33548286, 0.33441315,\n",
       "        0.33412453]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "hispanic-replacement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.32372288, 0.33490431, 0.33453344, ..., 1.15679968, 0.33415654,\n",
       "        0.33405415],\n",
       "       [0.92142793, 0.736381  , 0.33416588, ..., 0.33545675, 0.68191458,\n",
       "        0.5974671 ],\n",
       "       [1.16130358, 0.3346012 , 0.67129594, ..., 0.33548286, 0.33441315,\n",
       "        0.33412453]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "accessory-jungle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8317)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "effective-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_topics(model, feature_names, num_top_words):\n",
    "    for topic_idx, topic_scores in enumerate(model.components_):\n",
    "        print(\"***Topic {}:\".format(topic_idx))\n",
    "        print(\" + \".join([\"{:.2f} * {}\".format(topic_scores[i], feature_names[i]) for i in topic_scores.argsort()[::-1][:num_top_words]]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "stretch-macintosh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Topic 0:\n",
      "18.74 * climate + 14.35 * change + 12.48 * global + 10.34 * carbon + 9.03 * years + 9.01 * year + 8.93 * people + 8.60 * emissions + 8.57 * warming + 8.31 * many\n",
      "\n",
      "***Topic 1:\n",
      "23.11 * climate + 15.79 * change + 11.90 * ice + 9.19 * time + 8.44 * ocean + 8.21 * also + 7.88 * sea + 7.60 * world + 6.87 * may + 6.84 * emissions\n",
      "\n",
      "***Topic 2:\n",
      "11.51 * climate + 7.93 * change + 7.82 * carbon + 7.13 * one + 6.63 * water + 6.57 * species + 6.26 * could + 6.25 * energy + 6.22 * also + 6.21 * research\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_topics(lda, vectorizer.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "popular-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "exotic-footage",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el5871403717313241123603870479\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el5871403717313241123603870479_data = {\"mdsDat\": {\"x\": [-0.03870625952628449, 0.011031734316377674, 0.02767452520990681], \"y\": [0.00941675741291346, -0.03755931025862844, 0.028142552845714985], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [37.73728870230448, 33.122535069654965, 29.140176228040556]}, \"tinfo\": {\"Term\": [\"ice\", \"ocean\", \"city\", \"problems\", \"species\", \"four\", \"long\", \"surface\", \"importantly\", \"per\", \"despite\", \"term\", \"fossil\", \"often\", \"infrastructure\", \"2009\", \"shows\", \"electricity\", \"decades\", \"solutions\", \"specific\", \"particular\", \"droughts\", \"people\", \"better\", \"price\", \"exactly\", \"measures\", \"making\", \"words\", \"despite\", \"address\", \"comes\", \"19\", \"total\", \"huge\", \"value\", \"infrastructure\", \"flood\", \"worse\", \"landscape\", \"decades\", \"lot\", \"sense\", \"price\", \"meat\", \"2\\u00e2\", \"expect\", \"migration\", \"generations\", \"relatively\", \"reported\", \"standards\", \"period\", \"intense\", \"decisions\", \"per\", \"2016\", \"consumers\", \"better\", \"fossil\", \"think\", \"ability\", \"government\", \"end\", \"biodiversity\", \"means\", \"global\", \"cities\", \"see\", \"year\", \"weather\", \"environmental\", \"years\", \"future\", \"recent\", \"warming\", \"already\", \"current\", \"people\", \"data\", \"climate\", \"change\", \"carbon\", \"many\", \"new\", \"emissions\", \"would\", \"australia\", \"may\", \"world\", \"first\", \"also\", \"like\", \"one\", \"us\", \"ocean\", \"ice\", \"city\", \"importantly\", \"surface\", \"four\", \"droughts\", \"happened\", \"newsletter\", \"particular\", \"exactly\", \"livestock\", \"ask\", \"west\", \"degree\", \"try\", \"degrees\", \"combination\", \"futures\", \"glaciers\", \"facts\", \"extinction\", \"reason\", \"slow\", \"laws\", \"earth\\u00e2\", \"methods\", \"body\", \"multi\", \"accept\", \"break\", \"shows\", \"dry\", \"often\", \"deep\", \"changes\", \"climate\", \"best\", \"time\", \"change\", \"sea\", \"response\", \"little\", \"reduce\", \"increase\", \"trees\", \"world\", \"science\", \"likely\", \"also\", \"may\", \"use\", \"people\", \"emissions\", \"water\", \"political\", \"example\", \"high\", \"species\", \"since\", \"carbon\", \"would\", \"us\", \"research\", \"could\", \"problems\", \"specific\", \"solutions\", \"2009\", \"follow\", \"fully\", \"estimated\", \"measures\", \"electricity\", \"win\", \"blue\", \"sustainability\", \"inevitable\", \"correct\", \"residents\", \"fair\", \"contributed\", \"came\", \"obama\", \"vast\", \"care\", \"seasonal\", \"driver\", \"reverse\", \"16\", \"august\", \"insurance\", \"making\", \"agenda\", \"rice\", \"long\", \"words\", \"along\", \"2017\", \"however\", \"species\", \"second\", \"humans\", \"result\", \"industry\", \"term\", \"water\", \"one\", \"research\", \"countries\", \"energy\", \"take\", \"could\", \"carbon\", \"climate\", \"different\", \"also\", \"change\", \"new\", \"would\", \"australia\", \"global\", \"many\", \"even\", \"emissions\", \"evidence\", \"public\", \"us\", \"like\"], \"Freq\": [6.0, 4.0, 3.0, 2.0, 5.0, 2.0, 3.0, 2.0, 2.0, 5.0, 2.0, 4.0, 4.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 8.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.6057209651653914, 1.9848144993740215, 2.010786603314237, 1.881495951994882, 1.6415373032379095, 1.898933542711956, 1.7738253175191883, 2.5650280276035393, 1.5722496039201461, 1.604681070769077, 1.49279801907375, 2.55927944692753, 1.701398740159976, 2.1465114589426304, 2.4981886364691284, 1.3019220968642669, 1.3890401852632384, 1.3425872450925216, 1.4768194667537726, 1.2314996030100411, 1.237616510208353, 1.2890513698626864, 1.1954514514651062, 1.5660971046985155, 1.1881795838777298, 1.436619426741525, 4.042785222479275, 1.3984613390202045, 1.1238672432172694, 2.624671279813648, 3.2361864687994526, 2.2826208180663135, 1.6662778892566186, 3.959258379773788, 1.8448647810048953, 1.7309724058240699, 3.0877975964168787, 6.340983265679146, 2.8437301994058637, 2.432164641722774, 4.576153003202636, 3.206313085625486, 3.530989271870846, 4.5904335543386585, 3.757816382969396, 3.5496365936878034, 4.35679139595646, 3.5262045046221884, 2.846079013695927, 4.538435628079026, 3.10528921962139, 9.523963650305188, 7.29034977822739, 5.252483430140103, 4.222003472650887, 4.113937352618488, 4.367254912469157, 3.833078925885776, 3.6125498763499215, 3.60394984614827, 3.3600918918765976, 2.9879195274218646, 3.4169165166023325, 3.0788748757780087, 3.0381053906269653, 2.9256855359440674, 4.0325806585502235, 5.6832891843371955, 2.843672588048975, 2.1080730126718197, 2.3266631666108597, 2.5497572477899575, 1.7129071288227857, 1.5838797321214941, 1.5063809711481055, 1.8036721769106758, 1.7552704275102236, 1.413548063516289, 1.5076923296710223, 1.2693362299900062, 1.267448071938821, 1.7464314028607333, 1.3044068814814544, 1.2515628909143732, 1.2230673881177971, 1.3005633295926406, 1.1717849128127127, 1.346780298680093, 1.1962338558894547, 1.293184067394922, 1.342273911392668, 1.2678455399876394, 1.1774056645296729, 1.0382323789719563, 0.9917901558355705, 0.9635994938067642, 1.2788633751732221, 2.29994247758313, 1.6109909467279842, 2.60345092344384, 1.7907628669618265, 2.950868813012795, 11.041931508046478, 1.799727395861696, 4.391873780021703, 7.5431021352570085, 3.762740809145899, 2.061236566652312, 1.938491078917778, 1.9721425645155037, 2.6647914206299728, 2.083721848424173, 3.6319479076844106, 2.8762760648677532, 2.782313970669344, 3.921804735772044, 3.283824486307558, 2.5657251709816054, 3.246218204133687, 3.266029525303461, 2.767712733752417, 2.25506856500506, 2.41830501658277, 2.152576639701483, 2.4439264621570325, 2.27277052651733, 3.0276229977970734, 2.5873204492865667, 2.404008733427315, 2.308434727292685, 2.263899859821721, 2.241526674235886, 1.4233933113632817, 1.4484383578773663, 1.5471194036309037, 1.3083654704127958, 1.2059515491296395, 1.1469703430017129, 1.4605276101616784, 1.6276446888580998, 1.1692620205522581, 1.1458187891785154, 1.1553643971797838, 1.0480087085377685, 0.9706832623418863, 1.1545421448721063, 0.9747956309924364, 0.9815016262885354, 1.1895786417721252, 0.964906171443627, 0.8695896554182548, 0.8583352674765847, 0.9238730762507099, 0.8320209081736513, 1.0353531877335211, 0.7967762313564661, 0.7937929535803486, 1.1658373476432162, 1.5949353805792876, 0.8984316136468955, 0.7605757652130908, 2.667171856616629, 1.6339385494091745, 1.2589072292665404, 1.4348720684501146, 2.355353455200702, 2.9690580295460536, 1.4834472008342618, 1.9784794991151229, 1.7917695642134475, 2.096028852774149, 2.1127272657482936, 2.9957954267426685, 3.221078365291345, 2.8069468593433586, 2.399408882159308, 2.8244779637664785, 1.9362384595856286, 2.828079293408641, 3.5326818798408914, 5.203444713670088, 2.127274173854958, 2.8109158603290676, 3.583452797449073, 2.5587440047316954, 2.5738491590225014, 2.27673326020368, 2.4302692063229983, 2.2508345634284326, 2.0101926190699575, 2.2965184334026345, 1.8138883239954198, 1.767395860354742, 1.8217612133205392, 1.7831857512869687], \"Total\": [6.0, 4.0, 3.0, 2.0, 5.0, 2.0, 3.0, 2.0, 2.0, 5.0, 2.0, 4.0, 4.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 8.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.9602680729983297, 2.309592634188055, 2.3516514721223203, 2.2194016074393765, 1.9533873936679724, 2.2606631590417923, 2.1243328628411486, 3.0760171319676344, 1.9003377555434562, 1.945392422794313, 1.8099021781101594, 3.105675155171473, 2.0700192720460002, 2.6473365451556523, 3.1015659684302745, 1.6194118727423297, 1.7301989421485335, 1.6798336270585847, 1.8536808056528677, 1.5467198548083616, 1.5612347109487028, 1.6267529333569875, 1.5090058351884978, 1.9811941006349951, 1.5094296811294654, 1.8263548432187546, 5.14931321618837, 1.7855728084462386, 1.4378917494080943, 3.3679349725612715, 4.170663496615182, 2.976134167494222, 2.1530869059232116, 5.5214160853067575, 2.4148595793941987, 2.273967770853679, 4.467091804306722, 10.771279257701071, 4.127418949783252, 3.4654884436823554, 7.516906117960892, 4.880065161589014, 5.547683791375138, 7.763954451513312, 6.0813044251515604, 5.66087278723332, 7.442150384772088, 5.642045714270599, 4.269535202589553, 8.383640520770385, 4.905038525034915, 25.769339872021753, 18.416904710933473, 11.812788307778069, 8.609708019173166, 8.781362108236376, 9.929802871175252, 8.994248534194844, 7.947339247850026, 8.274227484792807, 8.260991942061686, 5.5571996657805025, 10.149637112703445, 6.757930300690404, 8.44557509265988, 7.151455482691921, 4.3753940421818225, 6.180786788022366, 3.2593035095947225, 2.434631549467467, 2.6968051237531037, 2.9638962879278634, 2.065530877344311, 1.9178975603518837, 1.8294148605936504, 2.2090612889160552, 2.173413265104687, 1.7519512867372558, 1.873949624868171, 1.5983786202547554, 1.59889300572318, 2.204850093645261, 1.6531042827874618, 1.588608797875505, 1.554554430676565, 1.6531079168244553, 1.492814549982397, 1.721368888903485, 1.5491813077573084, 1.6768968298660243, 1.755468316716959, 1.6674917713543984, 1.5556193465097528, 1.3730343712196167, 1.314560682369371, 1.2871448346591534, 1.711310082579741, 3.1128402718524764, 2.1778164193800453, 3.8437458019287165, 2.539181643605004, 4.650579079742303, 25.769339872021753, 2.597589898407603, 8.54785662215196, 18.416904710933473, 7.211963428578296, 3.1811387358978296, 2.920588305505583, 3.1041539278922308, 4.925131112823957, 3.4279407154459216, 8.260991942061686, 5.7451164745253624, 5.582867975802641, 10.149637112703445, 8.274227484792807, 5.228262964515402, 8.383640520770385, 9.929802871175252, 7.119191312358554, 4.3443260869215035, 5.257695391459465, 3.899579087627171, 5.793126546601059, 4.65180981210944, 11.812788307778069, 8.994248534194844, 7.151455482691921, 6.966424306905328, 7.748229169803765, 2.5839652426637585, 1.7630894800394805, 1.8053906960881916, 1.9367500271679596, 1.6560275090676797, 1.5524818850019209, 1.4783830270472773, 1.914555109294354, 2.1408807233890865, 1.5440223829936173, 1.5134792221944982, 1.5307406721721946, 1.3894059243215588, 1.3008203122920547, 1.547815746049313, 1.3078389166127922, 1.3210873752909942, 1.6120410572657737, 1.3124891378956585, 1.2092919090257626, 1.1953420467348743, 1.2877448206619317, 1.1662228272065398, 1.4534316891507375, 1.1265527757588634, 1.1260090360509039, 1.6552895799333098, 2.266262298896426, 1.288733793078831, 1.0913659700380716, 3.9527675954410695, 2.431873140904374, 1.881948003900882, 2.208785333032002, 3.979011021359551, 5.793126546601059, 2.39275451308107, 3.462126295362048, 3.0876592634537388, 3.9627678888173046, 4.083903908838721, 7.119191312358554, 8.44557509265988, 6.966424306905328, 5.416084769150633, 7.312007003173759, 3.869480788774838, 7.748229169803765, 11.812788307778069, 25.769339872021753, 4.791552652768922, 10.149637112703445, 18.416904710933473, 8.781362108236376, 8.994248534194844, 7.947339247850026, 10.771279257701071, 8.609708019173166, 5.917125395331141, 9.929802871175252, 4.586276173478099, 5.134716504187955, 7.151455482691921, 6.757930300690404], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -7.0162, -7.2884, -7.2754, -7.3419, -7.4783, -7.3326, -7.4008, -7.032, -7.5214, -7.501, -7.5733, -7.0342, -7.4425, -7.2101, -7.0584, -7.7101, -7.6453, -7.6793, -7.584, -7.7657, -7.7607, -7.72, -7.7954, -7.5253, -7.8015, -7.6116, -6.577, -7.6386, -7.8572, -7.009, -6.7995, -7.1486, -7.4633, -6.5979, -7.3615, -7.4253, -6.8465, -6.1269, -6.9288, -7.0852, -6.4531, -6.8088, -6.7124, -6.45, -6.6501, -6.7071, -6.5022, -6.7137, -6.928, -6.4614, -6.8408, -5.7201, -5.9874, -6.3152, -6.5336, -6.5596, -6.4998, -6.6303, -6.6895, -6.6919, -6.762, -6.8794, -6.7452, -6.8494, -6.8627, -6.9004, -6.4491, -6.106, -6.7984, -7.0977, -6.9991, -6.9075, -7.3053, -7.3836, -7.4338, -7.2537, -7.2809, -7.4974, -7.4329, -7.605, -7.6065, -7.2859, -7.5778, -7.6191, -7.6421, -7.5807, -7.685, -7.5458, -7.6643, -7.5864, -7.5491, -7.6062, -7.6802, -7.806, -7.8517, -7.8806, -7.5975, -7.0106, -7.3666, -6.8867, -7.2609, -6.7614, -5.4418, -7.2559, -6.3637, -5.8229, -6.5184, -7.1202, -7.1816, -7.1644, -6.8634, -7.1093, -6.5537, -6.787, -6.8202, -6.4769, -6.6545, -6.9013, -6.666, -6.6599, -6.8255, -7.0303, -6.9604, -7.0768, -6.9499, -7.0225, -6.7357, -6.8929, -6.9664, -7.0069, -7.0264, -6.9082, -7.3624, -7.3449, -7.279, -7.4466, -7.5281, -7.5783, -7.3366, -7.2283, -7.559, -7.5793, -7.571, -7.6685, -7.7452, -7.5717, -7.7409, -7.7341, -7.5418, -7.7511, -7.8551, -7.8682, -7.7946, -7.8993, -7.6807, -7.9426, -7.9463, -7.562, -7.2486, -7.8225, -7.9891, -6.7344, -7.2244, -7.4852, -7.3543, -6.8587, -6.6272, -7.321, -7.0331, -7.1322, -6.9754, -6.9674, -6.6182, -6.5457, -6.6833, -6.8402, -6.6771, -7.0547, -6.6758, -6.4533, -6.0661, -6.9606, -6.6819, -6.4391, -6.7759, -6.77, -6.8927, -6.8274, -6.9041, -7.0172, -6.884, -7.1199, -7.1459, -7.1156, -7.137], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.847, 0.823, 0.8179, 0.8094, 0.8006, 0.8002, 0.7942, 0.7929, 0.785, 0.782, 0.7819, 0.781, 0.7784, 0.7648, 0.7582, 0.7563, 0.7549, 0.7504, 0.7472, 0.7466, 0.7422, 0.7418, 0.7416, 0.7394, 0.7352, 0.7345, 0.7326, 0.7302, 0.7281, 0.7252, 0.7208, 0.7092, 0.7182, 0.6419, 0.7053, 0.7017, 0.6052, 0.4447, 0.602, 0.6204, 0.4782, 0.5545, 0.5227, 0.449, 0.4931, 0.5078, 0.4391, 0.5045, 0.569, 0.3608, 0.5174, -0.0209, 0.0478, 0.164, 0.2619, 0.2163, 0.1531, 0.1216, 0.1861, 0.1434, 0.0749, 0.354, -0.1142, 0.1884, -0.0479, 0.0807, 1.0234, 1.021, 0.9685, 0.9609, 0.9573, 0.9544, 0.9178, 0.9136, 0.9107, 0.9022, 0.8913, 0.8903, 0.8875, 0.8745, 0.8727, 0.8719, 0.868, 0.8665, 0.8651, 0.8651, 0.8628, 0.8596, 0.8464, 0.8451, 0.8366, 0.831, 0.8264, 0.8255, 0.8232, 0.8155, 0.8137, 0.8023, 0.8035, 0.7153, 0.7558, 0.6501, 0.2575, 0.738, 0.439, 0.2123, 0.4544, 0.671, 0.6951, 0.6513, 0.4907, 0.6072, 0.2832, 0.4131, 0.4085, 0.1541, 0.1808, 0.3931, 0.1562, -0.007, 0.1602, 0.4493, 0.3283, 0.5108, 0.2419, 0.3887, -0.2564, -0.141, 0.0148, 0.0004, -0.1254, 1.0909, 1.019, 1.0128, 1.0084, 0.9974, 0.9805, 0.9792, 0.9624, 0.959, 0.955, 0.9548, 0.9517, 0.9511, 0.9403, 0.9399, 0.9391, 0.9359, 0.9292, 0.9254, 0.9033, 0.9019, 0.901, 0.8954, 0.8939, 0.8867, 0.8834, 0.8825, 0.8818, 0.8723, 0.8719, 0.8397, 0.8354, 0.831, 0.8017, 0.7087, 0.5646, 0.755, 0.6735, 0.6888, 0.5962, 0.574, 0.3675, 0.2691, 0.324, 0.4189, 0.2819, 0.5407, 0.2252, 0.0259, -0.3668, 0.421, -0.0509, -0.4039, -0.0001, -0.0181, -0.017, -0.2558, -0.1085, 0.1534, -0.2311, 0.3055, 0.1665, -0.1345, -0.0993]}, \"token.table\": {\"Topic\": [3, 1, 3, 1, 1, 3, 1, 1, 2, 1, 3, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 1, 2, 1, 3, 2, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 2, 1, 2, 3, 2, 1, 1, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 1, 2, 2, 2, 1, 1, 2, 3, 3, 2, 2, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 2, 3, 1, 2, 3, 1, 3, 1, 3, 2, 3, 1, 2, 3, 2, 1, 2, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 2, 2, 1, 2, 3, 1, 3, 3, 1, 3, 1, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 2, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 3, 3, 1, 2, 1, 2, 1, 2, 3, 2, 3, 2, 1, 2, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 1, 2, 1, 3, 1, 2, 3, 2, 1, 2, 1, 2, 3, 1, 1, 1, 2, 3, 3, 1, 2, 1, 3, 3, 3, 1, 2, 3, 1, 2, 3, 3, 1, 3, 1, 2, 1, 1, 2, 1, 2, 3, 2, 3, 2, 3, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 2, 3, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3], \"Freq\": [0.8876636954060004, 0.9011438007866859, 1.032657788534811, 0.5600443707866359, 0.452737522766551, 0.452737522766551, 0.577968218358876, 0.9288988728220563, 0.7769133457811749, 0.865953575706266, 0.7759554419776363, 0.531364308645728, 0.7089627065379278, 0.17724067663448195, 0.17724067663448195, 0.29557707006540684, 0.3941027600872091, 0.29557707006540684, 1.0672645483416858, 0.8880923402774475, 0.5033131058400596, 0.2516565529200298, 0.2516565529200298, 0.384972239310381, 0.769944478620762, 0.8907535402082121, 0.2969178467360707, 0.8795199411507808, 0.6607292557013309, 0.7283138870818916, 0.5843476352880096, 0.6203315948392325, 0.42327009252402975, 0.25396205551441786, 0.3386160740192238, 0.8365806278893484, 0.38008558494872074, 0.4343835256556809, 0.21719176282784045, 0.21502698542552506, 0.6450809562765752, 0.21502698542552506, 0.7268464957155713, 0.24228216523852378, 0.9204420487900602, 0.38805805851694264, 0.4268638643686369, 0.19402902925847132, 0.6294815950518029, 0.8504661612101212, 0.695462645509753, 0.7569522036948777, 0.7687456834357028, 0.38718524378338426, 0.2581234958555895, 0.38718524378338426, 0.36927043893252176, 0.18463521946626088, 0.36927043893252176, 0.7026525974491189, 0.23421753248303964, 0.6116159913297817, 0.20387199710992723, 0.20387199710992723, 0.9659735323588153, 0.5475387237660821, 0.7876553475554035, 0.6254327190253106, 0.6049225148178805, 1.0134217327694337, 0.4174012360782989, 0.20870061803914944, 0.4174012360782989, 0.8574690673782348, 0.9682740751721102, 0.9183510520915882, 0.5997031092919656, 0.9341949685239505, 0.4028277350410861, 0.30212080128081453, 0.20141386752054305, 0.8282055060533697, 0.41028407093946395, 0.2735227139596426, 0.41028407093946395, 0.7210216282007118, 0.18025540705017795, 0.18025540705017795, 0.6764146920688511, 0.3380019631792971, 0.3380019631792971, 0.3380019631792971, 0.43608363830459385, 0.21804181915229692, 0.43608363830459385, 0.9202115548437428, 0.1901974012462547, 0.3803948024925094, 0.3803948024925094, 0.5952970484053327, 0.5809330042191024, 0.6698755716252844, 0.7646201587194907, 0.5398402397655535, 0.1799467465885178, 0.1799467465885178, 1.0524444900206924, 0.6038547032126211, 0.7193100096506787, 0.2397700032168929, 1.0121811657915256, 0.6441298991380906, 0.65775362000568, 0.32887681000284, 0.16443840500142, 0.6432711394767858, 0.6465294907098091, 0.6049211850131081, 0.5570368993738807, 0.18567896645796023, 0.18567896645796023, 0.7244518323197099, 0.18111295807992747, 0.18111295807992747, 1.0428085635778443, 0.25643793279455795, 0.5128758655891159, 0.25643793279455795, 0.2513187308685361, 0.2513187308685361, 0.5026374617370722, 0.884696152985358, 0.2888398384945186, 0.2888398384945186, 0.5776796769890372, 0.970750198280143, 0.8214795378123909, 0.40608055992508313, 0.6091208398876247, 0.20304027996254156, 0.25234887029894953, 0.5046977405978991, 0.7197320685733335, 0.9752871558556605, 0.6041239020185756, 0.6625018790221, 0.552516048709421, 0.5696485607157978, 0.44392289747254626, 0.29594859831503084, 0.29594859831503084, 0.3582388135754657, 0.5373582203631986, 0.17911940678773286, 0.34239676921081486, 0.6847935384216297, 0.5707921262253522, 0.25298729962099253, 0.7589618988629776, 0.9661745796323947, 0.8825103788621094, 0.464591829489723, 0.2322959147448615, 0.2322959147448615, 0.48342881644861657, 0.3625716123364624, 0.12085720411215414, 0.6715778702169722, 0.22385929007232408, 0.522314555034443, 0.6175081317062281, 0.6428307813499738, 0.53946720328034, 0.7607104133052229, 0.4555101988389986, 0.2277550994194993, 0.341632649129249, 1.093245738340069, 0.7619110673962004, 0.9142033749274318, 0.2601628857710152, 0.7804886573130457, 0.3552155971719824, 0.23681039811465496, 0.3552155971719824, 0.9053619336117932, 0.5963996175184934, 0.357839770511096, 0.11927992350369868, 0.7768026204785585, 0.19420065511963963, 0.19420065511963963, 1.0094922044028787, 0.46037059833536786, 0.46037059833536786, 0.6448355509304917, 0.7740042191659822, 0.38950543781117586, 0.19475271890558793, 0.38950543781117586, 0.6455022372091892, 0.7066048205536428, 0.3533024102768214, 0.32214897303079804, 0.6442979460615961, 0.32214897303079804, 0.6405186824166483, 0.6147214979575218, 0.2870913271845271, 0.2870913271845271, 0.4306369907767907, 0.6460717320859587, 0.3143528412374523, 0.6287056824749045, 0.3238699333946058, 0.6477398667892116, 0.6880268315770075, 0.9162829220019713, 0.3481217498145208, 0.5221826247217812, 0.1740608749072604, 0.41597548707916754, 0.5546339827722234, 0.13865849569305586, 0.7765513663537594, 0.4179283727323675, 0.4179283727323675, 0.5771192235963257, 0.28855961179816286, 0.7554762932048779, 0.3212500201319009, 0.6425000402638018, 0.214970095595231, 0.429940191190462, 0.214970095595231, 0.596339609086085, 0.5538967283739402, 0.34523671870648837, 0.5178550780597325, 0.5671861872703178, 0.662687960961453, 0.7416182883903119, 0.6532785194640134, 0.2584326049378376, 0.2584326049378376, 0.5168652098756752, 0.48972748738564476, 0.48972748738564476, 0.6720127142936955, 0.33600635714684773, 0.3509651755535339, 0.4679535674047119, 0.11698839185117797, 1.023862448628022, 0.5834406619076641, 0.29172033095383204, 0.9070911468150726, 0.4194950254896577, 0.27966335032643846, 0.27966335032643846, 0.38253622925513586, 0.5738043438827038, 0.19126811462756793, 0.9414720428158975, 0.8269301998436642, 0.5374790609156036, 0.2687395304578018, 0.1343697652289009, 0.14046539222285695, 0.4213961766685709, 0.4213961766685709, 0.6147458897911847, 0.20491529659706156, 0.6256339939285577, 0.6476590048268321, 0.4112056600239091, 0.8224113200478183, 0.36315251498130546, 0.48420335330840725, 0.12105083832710181, 1.0280702117299554, 0.4447286490686324, 0.3335464868014743, 0.3335464868014743, 0.6651672804656962, 0.2660669121862785, 0.13303345609313924, 0.6440017173240145, 0.2576006869296058, 0.2576006869296058], \"Term\": [\"16\", \"19\", \"2009\", \"2016\", \"2017\", \"2017\", \"2\\u00e2\", \"ability\", \"accept\", \"address\", \"agenda\", \"along\", \"already\", \"already\", \"already\", \"also\", \"also\", \"also\", \"ask\", \"august\", \"australia\", \"australia\", \"australia\", \"best\", \"best\", \"better\", \"better\", \"biodiversity\", \"blue\", \"body\", \"break\", \"came\", \"carbon\", \"carbon\", \"carbon\", \"care\", \"change\", \"change\", \"change\", \"changes\", \"changes\", \"changes\", \"cities\", \"cities\", \"city\", \"climate\", \"climate\", \"climate\", \"combination\", \"comes\", \"consumers\", \"contributed\", \"correct\", \"could\", \"could\", \"could\", \"countries\", \"countries\", \"countries\", \"current\", \"current\", \"data\", \"data\", \"data\", \"decades\", \"decisions\", \"deep\", \"degree\", \"degrees\", \"despite\", \"different\", \"different\", \"different\", \"driver\", \"droughts\", \"dry\", \"earth\\u00e2\", \"electricity\", \"emissions\", \"emissions\", \"emissions\", \"end\", \"energy\", \"energy\", \"energy\", \"environmental\", \"environmental\", \"environmental\", \"estimated\", \"even\", \"even\", \"even\", \"evidence\", \"evidence\", \"evidence\", \"exactly\", \"example\", \"example\", \"example\", \"expect\", \"extinction\", \"facts\", \"fair\", \"first\", \"first\", \"first\", \"flood\", \"follow\", \"fossil\", \"fossil\", \"four\", \"fully\", \"future\", \"future\", \"future\", \"futures\", \"generations\", \"glaciers\", \"global\", \"global\", \"global\", \"government\", \"government\", \"government\", \"happened\", \"high\", \"high\", \"high\", \"however\", \"however\", \"however\", \"huge\", \"humans\", \"humans\", \"humans\", \"ice\", \"importantly\", \"increase\", \"increase\", \"increase\", \"industry\", \"industry\", \"inevitable\", \"infrastructure\", \"insurance\", \"intense\", \"landscape\", \"laws\", \"like\", \"like\", \"like\", \"likely\", \"likely\", \"likely\", \"little\", \"little\", \"livestock\", \"long\", \"long\", \"lot\", \"making\", \"many\", \"many\", \"many\", \"may\", \"may\", \"may\", \"means\", \"means\", \"measures\", \"meat\", \"methods\", \"migration\", \"multi\", \"new\", \"new\", \"new\", \"newsletter\", \"obama\", \"ocean\", \"often\", \"often\", \"one\", \"one\", \"one\", \"particular\", \"people\", \"people\", \"people\", \"per\", \"per\", \"per\", \"period\", \"political\", \"political\", \"price\", \"problems\", \"public\", \"public\", \"public\", \"reason\", \"recent\", \"recent\", \"reduce\", \"reduce\", \"reduce\", \"relatively\", \"reported\", \"research\", \"research\", \"research\", \"residents\", \"response\", \"response\", \"result\", \"result\", \"reverse\", \"rice\", \"science\", \"science\", \"science\", \"sea\", \"sea\", \"sea\", \"seasonal\", \"second\", \"second\", \"see\", \"see\", \"sense\", \"shows\", \"shows\", \"since\", \"since\", \"since\", \"slow\", \"solutions\", \"species\", \"species\", \"specific\", \"standards\", \"surface\", \"sustainability\", \"take\", \"take\", \"take\", \"term\", \"term\", \"think\", \"think\", \"time\", \"time\", \"time\", \"total\", \"trees\", \"trees\", \"try\", \"us\", \"us\", \"us\", \"use\", \"use\", \"use\", \"value\", \"vast\", \"warming\", \"warming\", \"warming\", \"water\", \"water\", \"water\", \"weather\", \"weather\", \"west\", \"win\", \"words\", \"words\", \"world\", \"world\", \"world\", \"worse\", \"would\", \"would\", \"would\", \"year\", \"year\", \"year\", \"years\", \"years\", \"years\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el5871403717313241123603870479\", ldavis_el5871403717313241123603870479_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el5871403717313241123603870479\", ldavis_el5871403717313241123603870479_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el5871403717313241123603870479\", ldavis_el5871403717313241123603870479_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0     -0.038706  0.009417       1        1  37.737289\n",
       "1      0.011032 -0.037559       2        1  33.122535\n",
       "2      0.027675  0.028143       3        1  29.140176, topic_info=           Term      Freq     Total Category  logprob  loglift\n",
       "3735        ice  6.000000  6.000000  Default  30.0000  30.0000\n",
       "5094      ocean  4.000000  4.000000  Default  29.0000  29.0000\n",
       "1397       city  3.000000  3.000000  Default  28.0000  28.0000\n",
       "5727   problems  2.000000  2.000000  Default  27.0000  27.0000\n",
       "6953    species  5.000000  5.000000  Default  26.0000  26.0000\n",
       "...         ...       ...       ...      ...      ...      ...\n",
       "2545  emissions  2.296518  9.929803   Topic3  -6.8840  -0.2311\n",
       "2740   evidence  1.813888  4.586276   Topic3  -7.1199   0.3055\n",
       "5852     public  1.767396  5.134717   Topic3  -7.1459   0.1665\n",
       "7832         us  1.821761  7.151455   Topic3  -7.1156  -0.1345\n",
       "4369       like  1.783186  6.757930   Topic3  -7.1370  -0.0993\n",
       "\n",
       "[225 rows x 6 columns], token_table=      Topic      Freq   Term\n",
       "term                        \n",
       "33        3  0.887664     16\n",
       "48        1  0.901144     19\n",
       "106       3  1.032658   2009\n",
       "114       1  0.560044   2016\n",
       "116       1  0.452738   2017\n",
       "...     ...       ...    ...\n",
       "8196      2  0.266067   year\n",
       "8196      3  0.133033   year\n",
       "8198      1  0.644002  years\n",
       "8198      2  0.257601  years\n",
       "8198      3  0.257601  years\n",
       "\n",
       "[290 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2, 3])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.sklearn.prepare(lda, X, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-dodge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
